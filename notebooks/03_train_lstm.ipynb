{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "362a40d2-85eb-4eb7-9305-75a83695cb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_DIR: ..\\results\\2025-10-18_16-13-23_lstm\n"
     ]
    }
   ],
   "source": [
    "import os, sys, json, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = os.path.abspath(\"..\")\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)\n",
    "\n",
    "with open(os.path.join(ROOT, \"config.json\"), \"r\") as f:\n",
    "    C = json.load(f)\n",
    "\n",
    "TICKER   = C[\"ticker\"]; START = C[\"start\"]; END = C[\"end\"]; INTERVAL = C[\"interval\"]\n",
    "HORIZON  = int(C[\"horizon\"]); LOOKBACK = int(C[\"lookback\"])\n",
    "BATCH    = int(C[\"batch\"]);   EPOCHS   = int(C[\"epochs\"])\n",
    "SEED     = int(C.get(\"seed\", 42))\n",
    "FEATURESET = C.get(\"featureset\", \"v2\")\n",
    "EPS_MODE   = C.get(\"epsilon_mode\", \"abs\")\n",
    "EPSILON    = float(C.get(\"epsilon\", 0.001))  # 10bp\n",
    "\n",
    "RESULTS_DIR = Path(C.get(\"results_dir\", \"../results\"))\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RUN_DIR   = RESULTS_DIR / time.strftime(\"%Y-%m-%d_%H-%M-%S_lstm\")\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"RUN_DIR:\", RUN_DIR)\n",
    "\n",
    "# --> Train-CSV wie in Block 2 benannt\n",
    "eps_tag   = f\"{EPS_MODE}{str(EPSILON).replace('.','p')}\"\n",
    "TRAIN_CSV = f\"../data/{TICKER}_{INTERVAL}_{START}_{END}_cls_h{HORIZON}_{eps_tag}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27a371be-faf9-43d2-8bd0-53399c30ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    balanced_accuracy_score, matthews_corrcoef, average_precision_score,\n",
    "    roc_auc_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07b91fc5-71ec-46b3-b625-f02038552a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES (final): ['logret_1d', 'logret_3d', 'logret_5d', 'realized_vol_10', 'bb_pos', 'rsi_14', 'macd', 'macd_sig', 'macd_diff', 'vol_z_20', 'sma_diff']\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "df = pd.read_csv(TRAIN_CSV, index_col=0, parse_dates=True).sort_index()\n",
    "\n",
    "OHLCV = {\"open\",\"high\",\"low\",\"close\",\"volume\"}\n",
    "yaml_path = f\"../data/features_{FEATURESET}.yml\"\n",
    "\n",
    "with open(yaml_path, \"r\") as f:\n",
    "    meta = yaml.safe_load(f) or {}\n",
    "\n",
    "FEATURES = [c for c in meta.get(\"features\", []) if c in df.columns]\n",
    "assert len(FEATURES) > 0, f\"Keine nutzbaren Features in {yaml_path} gefunden.\"\n",
    "\n",
    "TARGET = \"target\"\n",
    "X = df[FEATURES].copy()\n",
    "y = df[TARGET].astype(int).copy()\n",
    "\n",
    "print(\"FEATURES (final):\", FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af24474a-6165-44f4-9243-a688d6372c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes → train 2381, val 510, test 511\n"
     ]
    }
   ],
   "source": [
    "# === 4) Chronologische Splits (70/15/15) ===\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "n = len(df)\n",
    "n_train = int(n * 0.70)\n",
    "n_val   = int(n * 0.15)\n",
    "n_test  = n - n_train - n_val\n",
    "\n",
    "train_idx = slice(0, n_train)\n",
    "val_idx   = slice(n_train, n_train + n_val)\n",
    "test_idx  = slice(n_train + n_val, n)\n",
    "\n",
    "X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "X_val,   y_val   = X.iloc[val_idx],   y.iloc[val_idx]\n",
    "X_test,  y_test  = X.iloc[test_idx],  y.iloc[test_idx]\n",
    "\n",
    "print(f\"Split sizes → train {len(X_train)}, val {len(X_val)}, test {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c6197b0-c082-48ba-9dd5-6de13a80ed3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape/check: (2381, 11)  | cols: ['logret_1d', 'logret_3d', 'logret_5d', 'realized_vol_10', 'bb_pos', 'rsi_14', 'macd', 'macd_sig', 'macd_diff', 'vol_z_20', 'sma_diff']\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape/check:\", X_train.shape, \" | cols:\", list(X_train.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e6af278-7df7-4bd2-beb7-ad8eea7e7bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\results\\\\2025-10-18_16-13-23_lstm\\\\scaler.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 5) Scaler nur auf TRAIN fitten ===\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_s = pd.DataFrame(scaler.fit_transform(X_train), index=X_train.index, columns=FEATURES)\n",
    "X_val_s   = pd.DataFrame(scaler.transform(X_val),       index=X_val.index,   columns=FEATURES)\n",
    "X_test_s  = pd.DataFrame(scaler.transform(X_test),      index=X_test.index,  columns=FEATURES)\n",
    "\n",
    "# Scaler speichern (für spätere Runs/Inference)\n",
    "import joblib, io\n",
    "joblib.dump(scaler, RUN_DIR / \"scaler.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b8a3e5d-4afb-4c23-b4a0-af4234725c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature  mean_diff  std_ratio\n",
      "8  macd_diff   0.144330   3.356402\n",
      "6       macd   0.088575   2.925897\n",
      "7   macd_sig   0.049833   2.866334\n",
      "2  logret_5d  -0.055026   1.067165\n",
      "1  logret_3d  -0.041238   1.064453\n"
     ]
    }
   ],
   "source": [
    "def drift_summary(Xa: pd.DataFrame, Xb: pd.DataFrame):\n",
    "    out = []\n",
    "    for c in Xa.columns:\n",
    "        m1, s1 = Xa[c].mean(), Xa[c].std(ddof=1)\n",
    "        m2, s2 = Xb[c].mean(), Xb[c].std(ddof=1)\n",
    "        ratio_std = float((s2 + 1e-9) / (s1 + 1e-9))\n",
    "        diff_mean = float(m2 - m1)\n",
    "        out.append({\"feature\": c, \"mean_diff\": diff_mean, \"std_ratio\": ratio_std})\n",
    "    return pd.DataFrame(out).sort_values(\"std_ratio\", ascending=False)\n",
    "\n",
    "drift_df = drift_summary(X_train_s, X_test_s)\n",
    "drift_df.to_csv(RUN_DIR / \"drift_train_vs_test.csv\", index=False)\n",
    "print(drift_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fd4bb55-1b73-42ce-8784-eb60d6b25384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warn-/Abbruchschwellen gegen Train→Test-Shift\n",
    "bad = drift_df[(drift_df[\"std_ratio\"] < 0.85) | (drift_df[\"mean_diff\"].abs() > 1.0)]\n",
    "if not bad.empty:\n",
    "    print(\"\\n[WARN] Starker Feature-Shift erkannt:\\n\", bad)\n",
    "    # Optional hart abbrechen:\n",
    "    # raise RuntimeError(\"Zu starker Drift in obigen Features – bitte Feature-Set stationär halten.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de930d62-f80e-408a-9471-fcdbb3c2b9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: \n",
      "  train: (2322, 60, 11) (2322,) \n",
      "  val  : (451, 60, 11) (451,) \n",
      "  test : (452, 60, 11) (452,)\n"
     ]
    }
   ],
   "source": [
    "# === 6) Windowing: Sequenzen der Länge LOOKBACK → Label am Endzeitpunkt ===\n",
    "def make_windows(X_df: pd.DataFrame, y_ser: pd.Series, lookback: int):\n",
    "    X_values = X_df.values.astype(np.float32)\n",
    "    y_values = y_ser.values.astype(np.int32)\n",
    "    n = len(X_df)\n",
    "    xs, ys = [], []\n",
    "    for i in range(lookback-1, n):\n",
    "        xs.append(X_values[i - lookback + 1 : i + 1])  # inkl. i\n",
    "        ys.append(y_values[i])                          # Label für Zeitpunkt i (Up/Down für i->i+H)\n",
    "    return np.stack(xs, axis=0), np.array(ys)\n",
    "\n",
    "Xtr_win, ytr = make_windows(X_train_s, y_train, LOOKBACK)\n",
    "Xva_win, yva = make_windows(X_val_s,   y_val,   LOOKBACK)\n",
    "Xte_win, yte = make_windows(X_test_s,  y_test,  LOOKBACK)\n",
    "\n",
    "print(\"Shapes:\",\n",
    "      \"\\n  train:\", Xtr_win.shape, ytr.shape,\n",
    "      \"\\n  val  :\", Xva_win.shape, yva.shape,\n",
    "      \"\\n  test :\", Xte_win.shape, yte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "212356d1-4801-4674-b38b-08bd67d9f0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weight: {0: 0.9880851063829788, 1: 1.012205754141238}\n"
     ]
    }
   ],
   "source": [
    "# === class_weight (optional) aus Trainingslabels berechnen ===\n",
    "from collections import Counter\n",
    "cw = None\n",
    "counts = Counter(ytr.tolist())\n",
    "if len(counts) == 2:\n",
    "    total = sum(counts.values())\n",
    "    # einfache Invers-Häufigkeit (normalisiert), robust bei leichter Schieflage\n",
    "    cw = {0: total/(2*counts.get(0, 1)), 1: total/(2*counts.get(1, 1))}\n",
    "print(\"class_weight:\", cw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a77b7452-9bcd-4b45-b92a-16a8e83f44ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7) tf.data Pipelines ===\n",
    "def to_ds(X, y, batch, shuffle):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(X), seed=SEED, reshuffle_each_iteration=True)\n",
    "    return ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_train = to_ds(Xtr_win, ytr, BATCH, shuffle=True)\n",
    "ds_val   = to_ds(Xva_win, yva, BATCH, shuffle=False)\n",
    "ds_test  = to_ds(Xte_win, yte, BATCH, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e49b799-942e-4630-b9fd-bf30e257a4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_rate_train: 0.494\n"
     ]
    }
   ],
   "source": [
    "# Basis-Rate im Training (für Output-Bias)\n",
    "pos_rate_train = float(ytr.mean())\n",
    "from math import log\n",
    "def _logit(p): \n",
    "    eps = 1e-6\n",
    "    p = min(max(p, eps), 1-eps)\n",
    "    return log(p/(1-p))\n",
    "output_bias_init = tf.keras.initializers.Constant(_logit(pos_rate_train))\n",
    "print(\"pos_rate_train:\", round(pos_rate_train,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da31a17d-1e28-458b-b4d5-886358ccd96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Diag] y_proba range: 0.214 .. 0.659, mean=0.493\n",
      "LogReg AUROC: 0.441\n",
      "LogReg MCC@0.5: -0.047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "\n",
    "logit = LogisticRegression(max_iter=200, n_jobs=None)\n",
    "logit.fit(X_train_s.iloc[LOOKBACK-1:], y_train.iloc[LOOKBACK-1:])  # grob: letztes Fensterende\n",
    "y_proba_lr = logit.predict_proba(X_test_s.iloc[LOOKBACK-1:])[:,1]\n",
    "\n",
    "print(f\"[Diag] y_proba range: {y_proba_lr.min():.3f} .. {y_proba_lr.max():.3f}, mean={y_proba_lr.mean():.3f}\")\n",
    "print(\"LogReg AUROC:\", round(roc_auc_score(y_test.iloc[LOOKBACK-1:], y_proba_lr), 3))\n",
    "print(\"LogReg MCC@0.5:\", round(matthews_corrcoef(y_test.iloc[LOOKBACK-1:], (y_proba_lr>=0.5).astype(int)), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76d25d1b-8215-40c9-9b57-e469739b9fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5247 - auc: 0.5138 - auprc: 0.5150 - loss: 0.7998 - prec: 0.5510 - rec: 0.3296\n",
      "Epoch 1: val_auprc improved from None to 0.46503, saving model to ..\\results\\2025-10-18_16-13-23_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - acc: 0.5129 - auc: 0.5071 - auprc: 0.5024 - loss: 0.7485 - prec: 0.5093 - rec: 0.3836 - val_acc: 0.4856 - val_auc: 0.4725 - val_auprc: 0.4650 - val_loss: 0.7142 - val_prec: 0.4675 - val_rec: 0.5324 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.4982 - auc: 0.5102 - auprc: 0.5055 - loss: 0.7005 - prec: 0.4953 - rec: 0.5154\n",
      "Epoch 2: val_auprc improved from 0.46503 to 0.46800, saving model to ..\\results\\2025-10-18_16-13-23_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.5146 - auc: 0.5172 - auprc: 0.5090 - loss: 0.6992 - prec: 0.5083 - rec: 0.5310 - val_acc: 0.4812 - val_auc: 0.4801 - val_auprc: 0.4680 - val_loss: 0.7052 - val_prec: 0.4437 - val_rec: 0.3287 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.5139 - auc: 0.5331 - auprc: 0.5169 - loss: 0.6949 - prec: 0.4985 - rec: 0.5340\n",
      "Epoch 3: val_auprc improved from 0.46800 to 0.46952, saving model to ..\\results\\2025-10-18_16-13-23_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.5220 - auc: 0.5370 - auprc: 0.5271 - loss: 0.6940 - prec: 0.5146 - rec: 0.5684 - val_acc: 0.4878 - val_auc: 0.4875 - val_auprc: 0.4695 - val_loss: 0.7022 - val_prec: 0.4522 - val_rec: 0.3287 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.5363 - auc: 0.5492 - auprc: 0.5356 - loss: 0.6885 - prec: 0.5287 - rec: 0.5021\n",
      "Epoch 4: val_auprc did not improve from 0.46952\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.5345 - auc: 0.5496 - auprc: 0.5417 - loss: 0.6889 - prec: 0.5306 - rec: 0.4987 - val_acc: 0.4967 - val_auc: 0.4900 - val_auprc: 0.4671 - val_loss: 0.7041 - val_prec: 0.4610 - val_rec: 0.3009 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.5500 - auc: 0.5681 - auprc: 0.5351 - loss: 0.6847 - prec: 0.5325 - rec: 0.5250\n",
      "Epoch 5: val_auprc improved from 0.46952 to 0.47792, saving model to ..\\results\\2025-10-18_16-13-23_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.5426 - auc: 0.5588 - auprc: 0.5567 - loss: 0.6870 - prec: 0.5381 - rec: 0.5231 - val_acc: 0.4989 - val_auc: 0.4987 - val_auprc: 0.4779 - val_loss: 0.7001 - val_prec: 0.4684 - val_rec: 0.3426 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5689 - auc: 0.5975 - auprc: 0.5804 - loss: 0.6786 - prec: 0.5578 - rec: 0.5452\n",
      "Epoch 6: val_auprc did not improve from 0.47792\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.5512 - auc: 0.5682 - auprc: 0.5605 - loss: 0.6850 - prec: 0.5513 - rec: 0.4917 - val_acc: 0.4989 - val_auc: 0.4891 - val_auprc: 0.4705 - val_loss: 0.7041 - val_prec: 0.4679 - val_rec: 0.3380 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5621 - auc: 0.5862 - auprc: 0.5636 - loss: 0.6806 - prec: 0.5483 - rec: 0.5462\n",
      "Epoch 7: val_auprc improved from 0.47792 to 0.48268, saving model to ..\\results\\2025-10-18_16-13-23_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.5521 - auc: 0.5716 - auprc: 0.5567 - loss: 0.6844 - prec: 0.5505 - rec: 0.5083 - val_acc: 0.4967 - val_auc: 0.5022 - val_auprc: 0.4827 - val_loss: 0.6993 - val_prec: 0.4678 - val_rec: 0.3704 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.5657 - auc: 0.6029 - auprc: 0.5869 - loss: 0.6763 - prec: 0.5556 - rec: 0.5049\n",
      "Epoch 8: val_auprc improved from 0.48268 to 0.48893, saving model to ..\\results\\2025-10-18_16-13-23_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.5547 - auc: 0.5842 - auprc: 0.5796 - loss: 0.6801 - prec: 0.5556 - rec: 0.4926 - val_acc: 0.5100 - val_auc: 0.5083 - val_auprc: 0.4889 - val_loss: 0.6985 - val_prec: 0.4818 - val_rec: 0.3056 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5708 - auc: 0.6108 - auprc: 0.5959 - loss: 0.6747 - prec: 0.5643 - rec: 0.5142\n",
      "Epoch 9: val_auprc improved from 0.48893 to 0.49468, saving model to ..\\results\\2025-10-18_16-13-23_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.5637 - auc: 0.5960 - auprc: 0.5807 - loss: 0.6789 - prec: 0.5638 - rec: 0.5161 - val_acc: 0.5033 - val_auc: 0.5103 - val_auprc: 0.4947 - val_loss: 0.6979 - val_prec: 0.4753 - val_rec: 0.3565 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5407 - auc: 0.5677 - auprc: 0.5513 - loss: 0.6847 - prec: 0.5320 - rec: 0.5275\n",
      "Epoch 10: val_auprc improved from 0.49468 to 0.50570, saving model to ..\\results\\2025-10-18_16-13-23_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.5556 - auc: 0.5912 - auprc: 0.5817 - loss: 0.6791 - prec: 0.5498 - rec: 0.5536 - val_acc: 0.5144 - val_auc: 0.5155 - val_auprc: 0.5057 - val_loss: 0.6973 - val_prec: 0.4903 - val_rec: 0.3519 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5605 - auc: 0.5912 - auprc: 0.5718 - loss: 0.6777 - prec: 0.5531 - rec: 0.5063\n",
      "Epoch 11: val_auprc improved from 0.50570 to 0.51347, saving model to ..\\results\\2025-10-18_16-13-23_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.5685 - auc: 0.5967 - auprc: 0.5841 - loss: 0.6781 - prec: 0.5739 - rec: 0.4908 - val_acc: 0.5299 - val_auc: 0.5297 - val_auprc: 0.5135 - val_loss: 0.6954 - val_prec: 0.5156 - val_rec: 0.3056 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5637 - auc: 0.5973 - auprc: 0.6118 - loss: 0.6775 - prec: 0.5808 - rec: 0.5592\n",
      "Epoch 12: val_auprc did not improve from 0.51347\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.5689 - auc: 0.6030 - auprc: 0.5948 - loss: 0.6757 - prec: 0.5630 - rec: 0.5684 - val_acc: 0.5233 - val_auc: 0.5292 - val_auprc: 0.5075 - val_loss: 0.6961 - val_prec: 0.5042 - val_rec: 0.2778 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5760 - auc: 0.6146 - auprc: 0.5866 - loss: 0.6757 - prec: 0.5914 - rec: 0.4434\n",
      "Epoch 13: val_auprc improved from 0.51347 to 0.51917, saving model to ..\\results\\2025-10-18_16-13-23_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.5810 - auc: 0.6240 - auprc: 0.6120 - loss: 0.6719 - prec: 0.5978 - rec: 0.4638 - val_acc: 0.5344 - val_auc: 0.5374 - val_auprc: 0.5192 - val_loss: 0.6932 - val_prec: 0.5188 - val_rec: 0.3843 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5932 - auc: 0.6328 - auprc: 0.6197 - loss: 0.6697 - prec: 0.5915 - rec: 0.5786\n",
      "Epoch 14: val_auprc improved from 0.51917 to 0.52154, saving model to ..\\results\\2025-10-18_16-13-23_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.5896 - auc: 0.6219 - auprc: 0.6022 - loss: 0.6717 - prec: 0.5833 - rec: 0.5920 - val_acc: 0.5211 - val_auc: 0.5407 - val_auprc: 0.5215 - val_loss: 0.6927 - val_prec: 0.5000 - val_rec: 0.4167 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m33/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5940 - auc: 0.6456 - auprc: 0.6283 - loss: 0.6642 - prec: 0.5980 - rec: 0.5194\n",
      "Epoch 15: val_auprc did not improve from 0.52154\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.5732 - auc: 0.6150 - auprc: 0.5980 - loss: 0.6726 - prec: 0.5813 - rec: 0.4865 - val_acc: 0.5322 - val_auc: 0.5281 - val_auprc: 0.5127 - val_loss: 0.6978 - val_prec: 0.5137 - val_rec: 0.4352 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5971 - auc: 0.6213 - auprc: 0.6051 - loss: 0.6709 - prec: 0.5900 - rec: 0.5861\n",
      "Epoch 16: val_auprc did not improve from 0.52154\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.5870 - auc: 0.6190 - auprc: 0.6015 - loss: 0.6714 - prec: 0.5844 - rec: 0.5676 - val_acc: 0.5255 - val_auc: 0.5278 - val_auprc: 0.5159 - val_loss: 0.6955 - val_prec: 0.5053 - val_rec: 0.4444 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6061 - auc: 0.6452 - auprc: 0.6240 - loss: 0.6642 - prec: 0.6034 - rec: 0.5829\n",
      "Epoch 17: val_auprc did not improve from 0.52154\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.5973 - auc: 0.6330 - auprc: 0.6139 - loss: 0.6680 - prec: 0.5962 - rec: 0.5728 - val_acc: 0.5432 - val_auc: 0.5331 - val_auprc: 0.5147 - val_loss: 0.6946 - val_prec: 0.5321 - val_rec: 0.3843 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.5984 - auc: 0.6574 - auprc: 0.6570 - loss: 0.6597 - prec: 0.6015 - rec: 0.5770\n",
      "Epoch 18: val_auprc did not improve from 0.52154\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.5840 - auc: 0.6272 - auprc: 0.6129 - loss: 0.6681 - prec: 0.5806 - rec: 0.5684 - val_acc: 0.5299 - val_auc: 0.5302 - val_auprc: 0.5135 - val_loss: 0.6960 - val_prec: 0.5105 - val_rec: 0.4491 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5971 - auc: 0.6380 - auprc: 0.6299 - loss: 0.6640 - prec: 0.5961 - rec: 0.5523\n",
      "Epoch 19: val_auprc did not improve from 0.52154\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.5956 - auc: 0.6356 - auprc: 0.6173 - loss: 0.6664 - prec: 0.6000 - rec: 0.5440 - val_acc: 0.5055 - val_auc: 0.5260 - val_auprc: 0.5163 - val_loss: 0.6962 - val_prec: 0.4844 - val_rec: 0.5046 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6070 - auc: 0.6351 - auprc: 0.5995 - loss: 0.6667 - prec: 0.5863 - rec: 0.5822\n",
      "Epoch 20: val_auprc improved from 0.52154 to 0.52391, saving model to ..\\results\\2025-10-18_16-13-23_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.6180 - auc: 0.6495 - auprc: 0.6305 - loss: 0.6624 - prec: 0.6182 - rec: 0.5929 - val_acc: 0.5144 - val_auc: 0.5389 - val_auprc: 0.5239 - val_loss: 0.6935 - val_prec: 0.4931 - val_rec: 0.4954 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6337 - auc: 0.6819 - auprc: 0.6601 - loss: 0.6537 - prec: 0.6166 - rec: 0.6470\n",
      "Epoch 21: val_auprc improved from 0.52391 to 0.52564, saving model to ..\\results\\2025-10-18_16-13-23_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.6090 - auc: 0.6531 - auprc: 0.6358 - loss: 0.6611 - prec: 0.6019 - rec: 0.6155 - val_acc: 0.5322 - val_auc: 0.5396 - val_auprc: 0.5256 - val_loss: 0.6938 - val_prec: 0.5118 - val_rec: 0.5000 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6018 - auc: 0.6497 - auprc: 0.6214 - loss: 0.6621 - prec: 0.5965 - rec: 0.5914\n",
      "Epoch 22: val_auprc did not improve from 0.52564\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.5999 - auc: 0.6452 - auprc: 0.6276 - loss: 0.6627 - prec: 0.5996 - rec: 0.5719 - val_acc: 0.5477 - val_auc: 0.5444 - val_auprc: 0.5227 - val_loss: 0.6926 - val_prec: 0.5353 - val_rec: 0.4213 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6069 - auc: 0.6587 - auprc: 0.6494 - loss: 0.6577 - prec: 0.5998 - rec: 0.5957\n",
      "Epoch 23: val_auprc improved from 0.52564 to 0.52570, saving model to ..\\results\\2025-10-18_16-13-23_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.6047 - auc: 0.6533 - auprc: 0.6386 - loss: 0.6587 - prec: 0.5986 - rec: 0.6059 - val_acc: 0.5100 - val_auc: 0.5394 - val_auprc: 0.5257 - val_loss: 0.6936 - val_prec: 0.4869 - val_rec: 0.4306 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6047 - auc: 0.6460 - auprc: 0.6345 - loss: 0.6597 - prec: 0.6076 - rec: 0.5791\n",
      "Epoch 24: val_auprc did not improve from 0.52570\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.6133 - auc: 0.6563 - auprc: 0.6362 - loss: 0.6576 - prec: 0.6115 - rec: 0.5955 - val_acc: 0.5344 - val_auc: 0.5427 - val_auprc: 0.5172 - val_loss: 0.6940 - val_prec: 0.5165 - val_rec: 0.4352 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6212 - auc: 0.6707 - auprc: 0.6445 - loss: 0.6525 - prec: 0.6211 - rec: 0.5916\n",
      "Epoch 25: val_auprc did not improve from 0.52570\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.6206 - auc: 0.6621 - auprc: 0.6466 - loss: 0.6549 - prec: 0.6157 - rec: 0.6173 - val_acc: 0.5255 - val_auc: 0.5372 - val_auprc: 0.5218 - val_loss: 0.6959 - val_prec: 0.5051 - val_rec: 0.4630 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6320 - auc: 0.6687 - auprc: 0.6693 - loss: 0.6554 - prec: 0.6458 - rec: 0.6164\n",
      "Epoch 26: val_auprc did not improve from 0.52570\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.6275 - auc: 0.6640 - auprc: 0.6504 - loss: 0.6542 - prec: 0.6277 - rec: 0.6042 - val_acc: 0.5188 - val_auc: 0.5280 - val_auprc: 0.5133 - val_loss: 0.6992 - val_prec: 0.4971 - val_rec: 0.4028 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6424 - auc: 0.6918 - auprc: 0.6578 - loss: 0.6428 - prec: 0.6349 - rec: 0.6022\n",
      "Epoch 27: val_auprc did not improve from 0.52570\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.6193 - auc: 0.6649 - auprc: 0.6498 - loss: 0.6526 - prec: 0.6163 - rec: 0.6077 - val_acc: 0.5322 - val_auc: 0.5270 - val_auprc: 0.5070 - val_loss: 0.7023 - val_prec: 0.5113 - val_rec: 0.5231 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6148 - auc: 0.6659 - auprc: 0.6419 - loss: 0.6542 - prec: 0.5978 - rec: 0.6589\n",
      "Epoch 28: val_auprc did not improve from 0.52570\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.6184 - auc: 0.6718 - auprc: 0.6507 - loss: 0.6510 - prec: 0.6120 - rec: 0.6216 - val_acc: 0.5122 - val_auc: 0.5288 - val_auprc: 0.5136 - val_loss: 0.7005 - val_prec: 0.4905 - val_rec: 0.4769 - learning_rate: 2.5000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6240 - auc: 0.6745 - auprc: 0.6519 - loss: 0.6503 - prec: 0.6217 - rec: 0.6105\n",
      "Epoch 29: val_auprc did not improve from 0.52570\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.6309 - auc: 0.6844 - auprc: 0.6637 - loss: 0.6467 - prec: 0.6328 - rec: 0.6024 - val_acc: 0.5322 - val_auc: 0.5432 - val_auprc: 0.5216 - val_loss: 0.6962 - val_prec: 0.5135 - val_rec: 0.4398 - learning_rate: 2.5000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6471 - auc: 0.6927 - auprc: 0.6576 - loss: 0.6437 - prec: 0.6306 - rec: 0.6294\n",
      "Epoch 30: val_auprc did not improve from 0.52570\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.6309 - auc: 0.6735 - auprc: 0.6514 - loss: 0.6497 - prec: 0.6321 - rec: 0.6051 - val_acc: 0.5299 - val_auc: 0.5365 - val_auprc: 0.5149 - val_loss: 0.6978 - val_prec: 0.5096 - val_rec: 0.4907 - learning_rate: 2.5000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6381 - auc: 0.6828 - auprc: 0.6650 - loss: 0.6479 - prec: 0.6302 - rec: 0.6591\n",
      "Epoch 31: val_auprc did not improve from 0.52570\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.6314 - auc: 0.6785 - auprc: 0.6580 - loss: 0.6482 - prec: 0.6222 - rec: 0.6460 - val_acc: 0.5255 - val_auc: 0.5389 - val_auprc: 0.5213 - val_loss: 0.6985 - val_prec: 0.5049 - val_rec: 0.4769 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m33/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6201 - auc: 0.6634 - auprc: 0.6318 - loss: 0.6520 - prec: 0.6111 - rec: 0.6066\n",
      "Epoch 32: val_auprc did not improve from 0.52570\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.6292 - auc: 0.6757 - auprc: 0.6524 - loss: 0.6493 - prec: 0.6347 - rec: 0.5876 - val_acc: 0.5299 - val_auc: 0.5426 - val_auprc: 0.5184 - val_loss: 0.6971 - val_prec: 0.5100 - val_rec: 0.4722 - learning_rate: 2.5000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6456 - auc: 0.6989 - auprc: 0.6892 - loss: 0.6405 - prec: 0.6501 - rec: 0.6638\n",
      "Epoch 33: val_auprc did not improve from 0.52570\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.6374 - auc: 0.6879 - auprc: 0.6663 - loss: 0.6428 - prec: 0.6225 - rec: 0.6757 - val_acc: 0.5366 - val_auc: 0.5419 - val_auprc: 0.5169 - val_loss: 0.6973 - val_prec: 0.5171 - val_rec: 0.4907 - learning_rate: 2.5000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6440 - auc: 0.6906 - auprc: 0.6826 - loss: 0.6418 - prec: 0.6553 - rec: 0.6112\n",
      "Epoch 34: val_auprc did not improve from 0.52570\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.6438 - auc: 0.6927 - auprc: 0.6725 - loss: 0.6416 - prec: 0.6404 - rec: 0.6364 - val_acc: 0.5388 - val_auc: 0.5441 - val_auprc: 0.5158 - val_loss: 0.6968 - val_prec: 0.5202 - val_rec: 0.4769 - learning_rate: 1.2500e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.6397 - auc: 0.7010 - auprc: 0.6993 - loss: 0.6372 - prec: 0.6517 - rec: 0.6064\n",
      "Epoch 35: val_auprc did not improve from 0.52570\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.6382 - auc: 0.6894 - auprc: 0.6688 - loss: 0.6428 - prec: 0.6357 - rec: 0.6269 - val_acc: 0.5299 - val_auc: 0.5404 - val_auprc: 0.5120 - val_loss: 0.6983 - val_prec: 0.5099 - val_rec: 0.4769 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "# === Modell: GRU + Regularisierung ============================================\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "n_features = X_train_s.shape[1]\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(LOOKBACK, n_features)),\n",
    "    layers.GRU(32, return_sequences=True, recurrent_dropout=0.10),\n",
    "    layers.LayerNormalization(),\n",
    "    layers.GRU(16, recurrent_dropout=0.10),\n",
    "    layers.LayerNormalization(),\n",
    "    layers.Dense(16, activation=\"relu\", kernel_regularizer=regularizers.l2(1e-5)),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n",
    "    loss=keras.losses.BinaryCrossentropy(),  # <-- BCE statt Focal\n",
    "    metrics=[\n",
    "        keras.metrics.AUC(name=\"auc\"),\n",
    "        keras.metrics.AUC(name=\"auprc\", curve=\"PR\"),\n",
    "        keras.metrics.BinaryAccuracy(name=\"acc\"),\n",
    "        keras.metrics.Precision(name=\"prec\"),\n",
    "        keras.metrics.Recall(name=\"rec\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "ckpt_path = RUN_DIR / \"best.keras\"\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(ckpt_path),\n",
    "        monitor=\"val_auprc\", mode=\"max\", save_best_only=True, verbose=1),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_auprc\", mode=\"max\", patience=12, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_auprc\", mode=\"max\", factor=0.5, patience=6, min_lr=1e-5, verbose=1),\n",
    "]\n",
    "\n",
    "# Datensätze wie gehabt: ds_train, ds_val, ds_test\n",
    "history = model.fit(\n",
    "    ds_train, validation_data=ds_val, epochs=EPOCHS,\n",
    "    callbacks=callbacks, verbose=1\n",
    ")\n",
    "pd.DataFrame(history.history).to_csv(RUN_DIR / \"history.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a055b6c-b605-4dd4-b1c9-060d2d961ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {\n",
      "  \"acc\": 0.4845132827758789,\n",
      "  \"auc\": 0.4905026853084564,\n",
      "  \"auprc\": 0.4944872260093689,\n",
      "  \"loss\": 0.7168943881988525,\n",
      "  \"prec\": 0.4882352948188782,\n",
      "  \"rec\": 0.3624454140663147\n",
      "}\n",
      "\n",
      "Confusion matrix (test):\n",
      " [[136  87]\n",
      " [146  83]]\n",
      "\n",
      "Classification report (test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.482     0.610     0.539       223\n",
      "           1      0.488     0.362     0.416       229\n",
      "\n",
      "    accuracy                          0.485       452\n",
      "   macro avg      0.485     0.486     0.477       452\n",
      "weighted avg      0.485     0.485     0.477       452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === 11) Evaluate & Berichte ===\n",
    "# Best Weights sind dank EarlyStopping bereits geladen\n",
    "test_metrics = model.evaluate(ds_test, return_dict=True, verbose=0)\n",
    "print(\"Test metrics:\", json.dumps(test_metrics, indent=2))\n",
    "\n",
    "# Schwellenwert 0.5 (später kalibrierbar)\n",
    "y_proba = model.predict(ds_test, verbose=0).ravel()\n",
    "y_pred  = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nConfusion matrix (test):\\n\", confusion_matrix(yte, y_pred))\n",
    "print(\"\\nClassification report (test):\\n\", classification_report(yte, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f537297-0c99-490a-8713-acb51b6620fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Val-basierte Schwelle (max MCC, Korridor) direkt in Block 3\n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score\n",
    "val_proba = model.predict(ds_val, verbose=0).ravel()\n",
    "\n",
    "def choose_threshold(y_true, y_prob, bounds=(0.35, 0.65)):\n",
    "    uniq = np.unique(y_prob); cand = np.r_[0.0, uniq, 1.0]\n",
    "    best_t, best_s = 0.5, -1\n",
    "    for t in cand:\n",
    "        yp = (y_prob >= t).astype(int)\n",
    "        pr = yp.mean()\n",
    "        if not (bounds[0] <= pr <= bounds[1]): \n",
    "            continue\n",
    "        s = matthews_corrcoef(y_true, yp)\n",
    "        if s > best_s: best_s, best_t = s, float(t)\n",
    "    return best_t\n",
    "\n",
    "thr = choose_threshold(yva, val_proba, bounds=(0.35,0.65))\n",
    "y_proba = model.predict(ds_test, verbose=0).ravel()\n",
    "y_pred  = (y_proba >= thr).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95bc992f-6ae8-43b7-bda5-4138cfa99a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proba stats  (test): min= 0.2499282956123352 max= 0.7504221200942993 mean= 0.4735203683376312\n",
      "AUROC val/test: 0.539 / 0.492\n"
     ]
    }
   ],
   "source": [
    "# --- Diagnose der Probabilitäten ---\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"Proba stats  (test): min=\", float(y_proba.min()), \n",
    "      \"max=\", float(y_proba.max()), \"mean=\", float(y_proba.mean()))\n",
    "\n",
    "# AUC auf VAL & TEST (Ranking-Qualität, unabhängig vom Threshold)\n",
    "val_proba = model.predict(ds_val, verbose=0).ravel()\n",
    "print(\"AUROC val/test:\", \n",
    "      round(roc_auc_score(yva, val_proba), 3), \"/\", \n",
    "      round(roc_auc_score(yte, y_proba), 3))\n",
    "\n",
    "# Quick check: Ist das Signal invertiert?\n",
    "if roc_auc_score(yva, val_proba) < 0.5:\n",
    "    print(\"⚠️ AUROC < 0.5 auf VAL → Versuch: invertiere Scores (1-p)\")\n",
    "    y_proba_inverted = 1.0 - y_proba\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    y_pred_inv = (y_proba_inverted >= 0.5).astype(int)\n",
    "    print(\"Confusion (inv, thr=0.5):\\n\", confusion_matrix(yte, y_pred_inv))\n",
    "    print(\"Report (inv):\\n\", classification_report(yte, y_pred_inv, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40b21880-6972-4be7-8000-3fe244cd2538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra test metrics: {\n",
      "  \"balanced_accuracy\": 0.48604774120273364,\n",
      "  \"mcc\": -0.02804768357113704,\n",
      "  \"auprc\": 0.49924492936590836\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# === Extra Test-Metriken ===\n",
    "bal_acc = balanced_accuracy_score(yte, y_pred)\n",
    "mcc = matthews_corrcoef(yte, y_pred)\n",
    "auprc_test = average_precision_score(yte, y_proba)  # probabilistische PR-Qualität\n",
    "\n",
    "extra = {\n",
    "    \"balanced_accuracy\": float(bal_acc),\n",
    "    \"mcc\": float(mcc),\n",
    "    \"auprc\": float(auprc_test)\n",
    "}\n",
    "print(\"Extra test metrics:\", json.dumps(extra, indent=2))\n",
    "\n",
    "# persistieren\n",
    "with open(RUN_DIR / \"extra_test_metrics.json\", \"w\") as f:\n",
    "    json.dump(extra, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "819bd95d-c17c-4736-9d00-4143c55fbfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = {\n",
    "    \"python\": sys.version, \"tensorflow\": tf.__version__,\n",
    "    \"seed\": SEED, \"lookback\": LOOKBACK, \"featureset\": FEATURESET,\n",
    "    \"features_used\": FEATURES,\n",
    "    \"batch\": BATCH, \"epochs\": EPOCHS,\n",
    "    \"cell\": \"GRU\", \"width1\": 32, \"width2\": 16,\n",
    "    \"dropout\": 0.10, \"lr\": 5e-4,\n",
    "    \"loss\": \"BCE\",\n",
    "    \"epsilon_mode\": EPS_MODE, \"epsilon\": EPSILON, \"horizon\": HORIZON\n",
    "}\n",
    "with open(RUN_DIR / \"env_info.json\", \"w\") as f: json.dump(env_info, f, indent=2)\n",
    "\n",
    "# Beim finalen Config-Dump\n",
    "with open(RUN_DIR / \"config.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"ticker\": TICKER, \"start\": START, \"end\": END, \"interval\": INTERVAL,\n",
    "        \"horizon\": HORIZON, \"lookback\": LOOKBACK,\n",
    "        \"featureset\": FEATURESET, \"features\": FEATURES,\n",
    "        \"scaler\": \"StandardScaler\", \"seed\": SEED, \"batch\": BATCH, \"epochs\": EPOCHS,\n",
    "        \"cell\": \"GRU\", \"width1\": 32, \"width2\": 16, \"dropout\": 0.10, \"lr\": 5e-4,\n",
    "        \"loss\": \"BCE\", \"epsilon_mode\": EPS_MODE, \"epsilon\": EPSILON\n",
    "    }, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "978a8ca1-2094-4e71-bce5-33df526f1e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Artefakte gespeichert in: ..\\results\\2025-10-18_16-13-23_lstm\n"
     ]
    }
   ],
   "source": [
    "# === 12) Artefakte sichern ===\n",
    "# Keras-Format (SavedModel) + Gewichte\n",
    "model.save(RUN_DIR / \"model.keras\")\n",
    "np.save(RUN_DIR / \"y_test.npy\", yte)\n",
    "np.save(RUN_DIR / \"y_proba.npy\", y_proba)\n",
    "with open(RUN_DIR / \"config.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"ticker\": TICKER, \"start\": START, \"end\": END, \"interval\": INTERVAL,\n",
    "        \"horizon\": HORIZON, \"lookback\": LOOKBACK, \"features\": FEATURES,\n",
    "        \"scaler\": \"StandardScaler\", \"seed\": SEED, \"batch\": BATCH, \"epochs\": EPOCHS\n",
    "    }, f, indent=2)\n",
    "print(f\"\\nArtefakte gespeichert in: {RUN_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c21f136-1586-402a-b44a-e1275cce874a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074624e-6803-4ed3-bae4-4e2b9ca3dbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (finance-lstm)",
   "language": "python",
   "name": "finance-lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
