{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "362a40d2-85eb-4eb7-9305-75a83695cb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_DIR: ..\\results\\2025-10-03_00-36-36_lstm\n"
     ]
    }
   ],
   "source": [
    "import os, sys, json, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = os.path.abspath(\"..\")\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)\n",
    "\n",
    "with open(os.path.join(ROOT, \"config.json\"), \"r\") as f:\n",
    "    C = json.load(f)\n",
    "\n",
    "TICKER   = C[\"ticker\"]; START = C[\"start\"]; END = C[\"end\"]; INTERVAL = C[\"interval\"]\n",
    "HORIZON  = int(C[\"horizon\"]); LOOKBACK = int(C[\"lookback\"])\n",
    "BATCH    = int(C[\"batch\"]);   EPOCHS   = int(C[\"epochs\"])\n",
    "SEED     = int(C.get(\"seed\", 42))\n",
    "\n",
    "RESULTS_DIR = Path(C.get(\"results_dir\", \"../results\"))\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RUN_DIR   = RESULTS_DIR / time.strftime(\"%Y-%m-%d_%H-%M-%S_lstm\")\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)   # <- hinzufügen\n",
    "print(\"RUN_DIR:\", RUN_DIR)                   # optional\n",
    "\n",
    "TRAIN_CSV = f\"../data/{TICKER}_{INTERVAL}_{START}_{END}_cls_h{HORIZON}.csv\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, matthews_corrcoef, average_precision_score\n",
    "import joblib\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "44414e9d-0397-49fc-9c80-2841f2950d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_CSV, index_col=0, parse_dates=[0]).sort_index()\n",
    "\n",
    "exp = {\"open\",\"high\",\"low\",\"close\",\"volume\",\"logret_1d\",\"target\"}\n",
    "missing = exp - set(df.columns)\n",
    "assert not missing, f\"Fehlende Spalten: {missing}\"\n",
    "assert not df.index.has_duplicates\n",
    "assert (df[\"close\"] > 0).all()\n",
    "assert df.notna().all().all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "07b91fc5-71ec-46b3-b625-f02038552a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES: ['logret_1d', 'vola_10d', 'sma_10', 'sma_20', 'sma_diff']\n"
     ]
    }
   ],
   "source": [
    "# === 3) Features / Ziel wählen (robust) ===\n",
    "import os, yaml\n",
    "\n",
    "OHLCV = {\"open\",\"high\",\"low\",\"close\",\"volume\"}\n",
    "\n",
    "# Kandidaten aus DF: alles außer OHLCV + target\n",
    "candidates_from_df = [c for c in df.columns if c not in OHLCV | {\"target\"}]\n",
    "\n",
    "# Optional: YAML lesen und mit DF schneiden\n",
    "features_yaml = \"../data/features_v1.yml\"\n",
    "if os.path.exists(features_yaml):\n",
    "    with open(features_yaml, \"r\") as f:\n",
    "        meta = yaml.safe_load(f)\n",
    "    yaml_feats = meta.get(\"features\", [])\n",
    "    FEATURES = [c for c in yaml_feats if c in candidates_from_df]\n",
    "    # Fallback, falls YAML-Features (noch) nicht alle im CSV sind:\n",
    "    if not FEATURES:\n",
    "        FEATURES = candidates_from_df\n",
    "else:\n",
    "    FEATURES = candidates_from_df\n",
    "\n",
    "# Sicherheit: nur numerische Spalten nehmen\n",
    "FEATURES = [c for c in FEATURES if pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "assert len(FEATURES) > 0, \"Keine nutzbaren Features gefunden – prüfe Block 2 Export.\"\n",
    "print(\"FEATURES:\", FEATURES)\n",
    "\n",
    "TARGET = \"target\"\n",
    "X = df[FEATURES].copy()\n",
    "y = df[TARGET].astype(int).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "af24474a-6165-44f4-9243-a688d6372c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes → train 2391, val 512, test 513\n"
     ]
    }
   ],
   "source": [
    "# === 4) Chronologische Splits (70/15/15) ===\n",
    "n = len(df)\n",
    "n_train = int(n * 0.70)\n",
    "n_val   = int(n * 0.15)\n",
    "n_test  = n - n_train - n_val\n",
    "\n",
    "train_idx = slice(0, n_train)\n",
    "val_idx   = slice(n_train, n_train + n_val)\n",
    "test_idx  = slice(n_train + n_val, n)\n",
    "\n",
    "X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "X_val,   y_val   = X.iloc[val_idx],   y.iloc[val_idx]\n",
    "X_test,  y_test  = X.iloc[test_idx],  y.iloc[test_idx]\n",
    "\n",
    "print(f\"Split sizes → train {len(X_train)}, val {len(X_val)}, test {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5c6197b0-c082-48ba-9dd5-6de13a80ed3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape/check: (2391, 5)  | cols: ['logret_1d', 'vola_10d', 'sma_10', 'sma_20', 'sma_diff']\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape/check:\", X_train.shape, \" | cols:\", list(X_train.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3e6af278-7df7-4bd2-beb7-ad8eea7e7bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\results\\\\2025-10-03_00-36-36_lstm\\\\scaler.joblib']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 5) Scaler nur auf TRAIN fitten ===\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_s = pd.DataFrame(scaler.fit_transform(X_train), index=X_train.index, columns=FEATURES)\n",
    "X_val_s   = pd.DataFrame(scaler.transform(X_val),       index=X_val.index,   columns=FEATURES)\n",
    "X_test_s  = pd.DataFrame(scaler.transform(X_test),      index=X_test.index,  columns=FEATURES)\n",
    "\n",
    "# Scaler speichern (für spätere Runs/Inference)\n",
    "import joblib, io\n",
    "joblib.dump(scaler, RUN_DIR / \"scaler.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2b8a3e5d-4afb-4c23-b4a0-af4234725c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature  mean_diff  std_ratio\n",
      "1   vola_10d  -0.104683   0.999691\n",
      "0  logret_1d  -0.025615   0.956340\n",
      "4   sma_diff  -0.139882   0.915933\n",
      "2     sma_10   5.075310   0.730956\n",
      "3     sma_20   5.125317   0.724050\n"
     ]
    }
   ],
   "source": [
    "def drift_summary(Xa: pd.DataFrame, Xb: pd.DataFrame):\n",
    "    out = []\n",
    "    for c in Xa.columns:\n",
    "        m1, s1 = Xa[c].mean(), Xa[c].std(ddof=1)\n",
    "        m2, s2 = Xb[c].mean(), Xb[c].std(ddof=1)\n",
    "        ratio_std = float((s2 + 1e-9) / (s1 + 1e-9))\n",
    "        diff_mean = float(m2 - m1)\n",
    "        out.append({\"feature\": c, \"mean_diff\": diff_mean, \"std_ratio\": ratio_std})\n",
    "    return pd.DataFrame(out).sort_values(\"std_ratio\", ascending=False)\n",
    "\n",
    "drift_df = drift_summary(X_train_s, X_test_s)\n",
    "drift_df.to_csv(RUN_DIR / \"drift_train_vs_test.csv\", index=False)\n",
    "print(drift_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "de930d62-f80e-408a-9471-fcdbb3c2b9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: \n",
      "  train: (2332, 60, 5) (2332,) \n",
      "  val  : (453, 60, 5) (453,) \n",
      "  test : (454, 60, 5) (454,)\n"
     ]
    }
   ],
   "source": [
    "# === 6) Windowing: Sequenzen der Länge LOOKBACK → Label am Endzeitpunkt ===\n",
    "def make_windows(X_df: pd.DataFrame, y_ser: pd.Series, lookback: int):\n",
    "    X_values = X_df.values.astype(np.float32)\n",
    "    y_values = y_ser.values.astype(np.int32)\n",
    "    n = len(X_df)\n",
    "    xs, ys = [], []\n",
    "    for i in range(lookback-1, n):\n",
    "        xs.append(X_values[i - lookback + 1 : i + 1])  # inkl. i\n",
    "        ys.append(y_values[i])                          # Label für Zeitpunkt i (Up/Down für i->i+H)\n",
    "    return np.stack(xs, axis=0), np.array(ys)\n",
    "\n",
    "Xtr_win, ytr = make_windows(X_train_s, y_train, LOOKBACK)\n",
    "Xva_win, yva = make_windows(X_val_s,   y_val,   LOOKBACK)\n",
    "Xte_win, yte = make_windows(X_test_s,  y_test,  LOOKBACK)\n",
    "\n",
    "print(\"Shapes:\",\n",
    "      \"\\n  train:\", Xtr_win.shape, ytr.shape,\n",
    "      \"\\n  val  :\", Xva_win.shape, yva.shape,\n",
    "      \"\\n  test :\", Xte_win.shape, yte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "212356d1-4801-4674-b38b-08bd67d9f0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weight: {0: 1.052346570397112, 1: 0.9526143790849673}\n"
     ]
    }
   ],
   "source": [
    "# === class_weight (optional) aus Trainingslabels berechnen ===\n",
    "from collections import Counter\n",
    "cw = None\n",
    "counts = Counter(ytr.tolist())\n",
    "if len(counts) == 2:\n",
    "    total = sum(counts.values())\n",
    "    # einfache Invers-Häufigkeit (normalisiert), robust bei leichter Schieflage\n",
    "    cw = {0: total/(2*counts.get(0, 1)), 1: total/(2*counts.get(1, 1))}\n",
    "print(\"class_weight:\", cw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a77b7452-9bcd-4b45-b92a-16a8e83f44ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7) tf.data Pipelines ===\n",
    "def to_ds(X, y, batch, shuffle):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(X), seed=SEED, reshuffle_each_iteration=True)\n",
    "    return ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_train = to_ds(Xtr_win, ytr, BATCH, shuffle=True)\n",
    "ds_val   = to_ds(Xva_win, yva, BATCH, shuffle=False)\n",
    "ds_test  = to_ds(Xte_win, yte, BATCH, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6e49b799-942e-4630-b9fd-bf30e257a4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_rate_train: 0.525\n"
     ]
    }
   ],
   "source": [
    "# Basis-Rate im Training (für Output-Bias)\n",
    "pos_rate_train = float(ytr.mean())\n",
    "from math import log\n",
    "def _logit(p): \n",
    "    eps = 1e-6\n",
    "    p = min(max(p, eps), 1-eps)\n",
    "    return log(p/(1-p))\n",
    "output_bias_init = tf.keras.initializers.Constant(_logit(pos_rate_train))\n",
    "print(\"pos_rate_train:\", round(pos_rate_train,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "da31a17d-1e28-458b-b4d5-886358ccd96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg AUROC: 0.472\n",
      "LogReg MCC@0.5: -0.052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "\n",
    "logit = LogisticRegression(max_iter=200, n_jobs=None)\n",
    "logit.fit(X_train_s.iloc[LOOKBACK-1:], y_train.iloc[LOOKBACK-1:])  # grob: letztes Fensterende\n",
    "y_proba_lr = logit.predict_proba(X_test_s.iloc[LOOKBACK-1:])[:,1]\n",
    "print(\"LogReg AUROC:\", round(roc_auc_score(y_test.iloc[LOOKBACK-1:], y_proba_lr), 3))\n",
    "print(\"LogReg MCC@0.5:\", round(matthews_corrcoef(y_test.iloc[LOOKBACK-1:], (y_proba_lr>=0.5).astype(int)), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "76d25d1b-8215-40c9-9b57-e469739b9fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,920</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ layer_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ layer_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_18 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m17,920\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ layer_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_19 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ layer_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,073</span> (121.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,073\u001b[0m (121.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,073</span> (121.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,073\u001b[0m (121.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 8) Modell definieren ===\n",
    "n_features = Xtr_win.shape[-1]\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(LOOKBACK, n_features)),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.LayerNormalization(),          # NEU: stabilisiert Sequenzstatistiken\n",
    "    layers.Dropout(0.1),                  # weniger Dropout (0.2 -> 0.1)\n",
    "    layers.LSTM(32),\n",
    "    layers.LayerNormalization(),          # NEU\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\", \n",
    "                 bias_initializer=output_bias_init),  # NEU: sinnvoller Startpunkt\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5e-4),  # 1e-3 -> 5e-4\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        keras.metrics.BinaryAccuracy(name=\"acc\"),\n",
    "        keras.metrics.AUC(name=\"auc\"),\n",
    "        keras.metrics.AUC(name=\"auprc\", curve=\"PR\"),\n",
    "        keras.metrics.Precision(name=\"prec\"),\n",
    "        keras.metrics.Recall(name=\"rec\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "ckpt_path = RUN_DIR / \"best.keras\"\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(ckpt_path),\n",
    "        monitor=\"val_auprc\", mode=\"max\", save_best_only=True, verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_auprc\", mode=\"max\", patience=12, restore_best_weights=True\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_auprc\", mode=\"max\", factor=0.5, patience=6, min_lr=1e-5, verbose=1\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "400bb060-c145-413b-a38e-9c4221173f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 9) Callbacks ===\n",
    "ckpt_path = RUN_DIR / \"best.keras\"\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(ckpt_path),\n",
    "        monitor=\"val_auc\",\n",
    "        mode=\"max\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1,\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_auc\", mode=\"max\", patience=10, restore_best_weights=True\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_auc\", mode=\"max\", factor=0.5, patience=5, verbose=1\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b9ee003a-f770-44c4-8444-4b8096ee3434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m33/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5141 - auc: 0.5159 - auprc: 0.5372 - loss: 0.7337 - prec: 0.5302 - rec: 0.5659\n",
      "Epoch 1: val_auc improved from None to 0.49791, saving model to ..\\results\\2025-10-03_00-36-36_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - acc: 0.5017 - auc: 0.4991 - auprc: 0.5311 - loss: 0.7167 - prec: 0.5258 - rec: 0.5163 - val_acc: 0.5121 - val_auc: 0.4979 - val_auprc: 0.5138 - val_loss: 0.6978 - val_prec: 0.5103 - val_rec: 0.9739 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5269 - auc: 0.5314 - auprc: 0.5625 - loss: 0.6967 - prec: 0.5490 - rec: 0.6127\n",
      "Epoch 2: val_auc improved from 0.49791 to 0.50060, saving model to ..\\results\\2025-10-03_00-36-36_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.5300 - auc: 0.5350 - auprc: 0.5563 - loss: 0.6973 - prec: 0.5496 - rec: 0.5792 - val_acc: 0.5011 - val_auc: 0.5006 - val_auprc: 0.5265 - val_loss: 0.7046 - val_prec: 0.5046 - val_rec: 0.9478 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5382 - auc: 0.5665 - auprc: 0.5731 - loss: 0.6889 - prec: 0.5778 - rec: 0.4117\n",
      "Epoch 3: val_auc improved from 0.50060 to 0.52199, saving model to ..\\results\\2025-10-03_00-36-36_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.5270 - auc: 0.5469 - auprc: 0.5640 - loss: 0.6921 - prec: 0.5676 - rec: 0.4150 - val_acc: 0.5143 - val_auc: 0.5220 - val_auprc: 0.5398 - val_loss: 0.6925 - val_prec: 0.5500 - val_rec: 0.2391 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5683 - auc: 0.5799 - auprc: 0.5991 - loss: 0.6836 - prec: 0.5797 - rec: 0.6626\n",
      "Epoch 4: val_auc improved from 0.52199 to 0.52583, saving model to ..\\results\\2025-10-03_00-36-36_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - acc: 0.5425 - auc: 0.5579 - auprc: 0.5826 - loss: 0.6882 - prec: 0.5610 - rec: 0.5899 - val_acc: 0.4923 - val_auc: 0.5258 - val_auprc: 0.5375 - val_loss: 0.7107 - val_prec: 0.0000e+00 - val_rec: 0.0000e+00 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5362 - auc: 0.5542 - auprc: 0.5609 - loss: 0.6903 - prec: 0.5671 - rec: 0.4466\n",
      "Epoch 5: val_auc did not improve from 0.52583\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5322 - auc: 0.5426 - auprc: 0.5675 - loss: 0.6911 - prec: 0.5635 - rec: 0.4820 - val_acc: 0.4967 - val_auc: 0.5221 - val_auprc: 0.5544 - val_loss: 0.6921 - val_prec: 0.5026 - val_rec: 0.8565 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5443 - auc: 0.5641 - auprc: 0.5711 - loss: 0.6888 - prec: 0.5632 - rec: 0.5043\n",
      "Epoch 6: val_auc did not improve from 0.52583\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5326 - auc: 0.5544 - auprc: 0.5749 - loss: 0.6891 - prec: 0.5684 - rec: 0.4551 - val_acc: 0.5011 - val_auc: 0.5155 - val_auprc: 0.5531 - val_loss: 0.6964 - val_prec: 0.8333 - val_rec: 0.0217 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5369 - auc: 0.5747 - auprc: 0.5751 - loss: 0.6853 - prec: 0.5463 - rec: 0.5454\n",
      "Epoch 7: val_auc did not improve from 0.52583\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5420 - auc: 0.5705 - auprc: 0.5911 - loss: 0.6841 - prec: 0.5662 - rec: 0.5449 - val_acc: 0.5121 - val_auc: 0.5246 - val_auprc: 0.5477 - val_loss: 0.6936 - val_prec: 0.5818 - val_rec: 0.1391 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5701 - auc: 0.5902 - auprc: 0.6216 - loss: 0.6778 - prec: 0.6028 - rec: 0.5861\n",
      "Epoch 8: val_auc improved from 0.52583 to 0.52883, saving model to ..\\results\\2025-10-03_00-36-36_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.5545 - auc: 0.5728 - auprc: 0.5962 - loss: 0.6841 - prec: 0.5890 - rec: 0.5000 - val_acc: 0.4923 - val_auc: 0.5288 - val_auprc: 0.5430 - val_loss: 0.7049 - val_prec: 0.0000e+00 - val_rec: 0.0000e+00 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5459 - auc: 0.5942 - auprc: 0.6185 - loss: 0.6784 - prec: 0.5841 - rec: 0.4946\n",
      "Epoch 9: val_auc improved from 0.52883 to 0.54406, saving model to ..\\results\\2025-10-03_00-36-36_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.5407 - auc: 0.5725 - auprc: 0.6035 - loss: 0.6823 - prec: 0.5657 - rec: 0.5384 - val_acc: 0.4945 - val_auc: 0.5441 - val_auprc: 0.5500 - val_loss: 0.6943 - val_prec: 0.5217 - val_rec: 0.0522 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5752 - auc: 0.5981 - auprc: 0.6196 - loss: 0.6781 - prec: 0.6067 - rec: 0.5269\n",
      "Epoch 10: val_auc did not improve from 0.54406\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5635 - auc: 0.5908 - auprc: 0.6195 - loss: 0.6784 - prec: 0.5945 - rec: 0.5294 - val_acc: 0.4989 - val_auc: 0.5343 - val_auprc: 0.5411 - val_loss: 0.6923 - val_prec: 0.5038 - val_rec: 0.8609 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5824 - auc: 0.6001 - auprc: 0.6215 - loss: 0.6760 - prec: 0.6052 - rec: 0.6071\n",
      "Epoch 11: val_auc did not improve from 0.54406\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5703 - auc: 0.5928 - auprc: 0.6111 - loss: 0.6787 - prec: 0.5965 - rec: 0.5605 - val_acc: 0.4989 - val_auc: 0.5404 - val_auprc: 0.5456 - val_loss: 0.6986 - val_prec: 0.7143 - val_rec: 0.0217 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5545 - auc: 0.5866 - auprc: 0.5919 - loss: 0.6812 - prec: 0.5805 - rec: 0.4658\n",
      "Epoch 12: val_auc did not improve from 0.54406\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5686 - auc: 0.6024 - auprc: 0.6187 - loss: 0.6758 - prec: 0.6009 - rec: 0.5302 - val_acc: 0.5475 - val_auc: 0.5382 - val_auprc: 0.5430 - val_loss: 0.6918 - val_prec: 0.5465 - val_rec: 0.6391 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5506 - auc: 0.5842 - auprc: 0.6135 - loss: 0.6813 - prec: 0.5686 - rec: 0.5701\n",
      "Epoch 13: val_auc did not improve from 0.54406\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - acc: 0.5519 - auc: 0.5907 - auprc: 0.6184 - loss: 0.6775 - prec: 0.5758 - rec: 0.5556 - val_acc: 0.5386 - val_auc: 0.5349 - val_auprc: 0.5405 - val_loss: 0.6924 - val_prec: 0.5396 - val_rec: 0.6217 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5872 - auc: 0.6195 - auprc: 0.6527 - loss: 0.6688 - prec: 0.6163 - rec: 0.5507\n",
      "Epoch 14: val_auc did not improve from 0.54406\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.5708 - auc: 0.6040 - auprc: 0.6328 - loss: 0.6740 - prec: 0.5989 - rec: 0.5515 - val_acc: 0.4923 - val_auc: 0.5411 - val_auprc: 0.5426 - val_loss: 0.7032 - val_prec: 0.5000 - val_rec: 0.0087 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5858 - auc: 0.6346 - auprc: 0.6604 - loss: 0.6651 - prec: 0.6254 - rec: 0.5412\n",
      "Epoch 15: val_auc did not improve from 0.54406\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5785 - auc: 0.6192 - auprc: 0.6397 - loss: 0.6704 - prec: 0.6054 - rec: 0.5654 - val_acc: 0.5254 - val_auc: 0.5396 - val_auprc: 0.5426 - val_loss: 0.6932 - val_prec: 0.5630 - val_rec: 0.2913 - learning_rate: 2.5000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5822 - auc: 0.6233 - auprc: 0.6509 - loss: 0.6680 - prec: 0.6054 - rec: 0.6163\n",
      "Epoch 16: val_auc improved from 0.54406 to 0.54450, saving model to ..\\results\\2025-10-03_00-36-36_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.5832 - auc: 0.6256 - auprc: 0.6514 - loss: 0.6679 - prec: 0.6024 - rec: 0.6054 - val_acc: 0.5166 - val_auc: 0.5445 - val_auprc: 0.5465 - val_loss: 0.6934 - val_prec: 0.5965 - val_rec: 0.1478 - learning_rate: 2.5000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5968 - auc: 0.6435 - auprc: 0.6614 - loss: 0.6628 - prec: 0.6120 - rec: 0.5628\n",
      "Epoch 17: val_auc improved from 0.54450 to 0.54710, saving model to ..\\results\\2025-10-03_00-36-36_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.5759 - auc: 0.6257 - auprc: 0.6554 - loss: 0.6664 - prec: 0.6061 - rec: 0.5482 - val_acc: 0.5386 - val_auc: 0.5471 - val_auprc: 0.5485 - val_loss: 0.6921 - val_prec: 0.6154 - val_rec: 0.2435 - learning_rate: 2.5000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5934 - auc: 0.6392 - auprc: 0.6613 - loss: 0.6634 - prec: 0.6066 - rec: 0.6145\n",
      "Epoch 18: val_auc improved from 0.54710 to 0.55125, saving model to ..\\results\\2025-10-03_00-36-36_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.5853 - auc: 0.6259 - auprc: 0.6461 - loss: 0.6674 - prec: 0.6094 - rec: 0.5850 - val_acc: 0.5143 - val_auc: 0.5512 - val_auprc: 0.5504 - val_loss: 0.6943 - val_prec: 0.6250 - val_rec: 0.1087 - learning_rate: 2.5000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5874 - auc: 0.6208 - auprc: 0.6680 - loss: 0.6657 - prec: 0.6161 - rec: 0.6087\n",
      "Epoch 19: val_auc did not improve from 0.55125\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.5905 - auc: 0.6319 - auprc: 0.6575 - loss: 0.6657 - prec: 0.6096 - rec: 0.6111 - val_acc: 0.4989 - val_auc: 0.5470 - val_auprc: 0.5452 - val_loss: 0.6940 - val_prec: 0.5294 - val_rec: 0.1174 - learning_rate: 2.5000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5961 - auc: 0.6278 - auprc: 0.6472 - loss: 0.6666 - prec: 0.6171 - rec: 0.6078\n",
      "Epoch 20: val_auc did not improve from 0.55125\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5802 - auc: 0.6151 - auprc: 0.6387 - loss: 0.6701 - prec: 0.6113 - rec: 0.5498 - val_acc: 0.5011 - val_auc: 0.5445 - val_auprc: 0.5427 - val_loss: 0.6948 - val_prec: 0.5417 - val_rec: 0.1130 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.6138 - auc: 0.6503 - auprc: 0.6781 - loss: 0.6603 - prec: 0.6210 - rec: 0.6744\n",
      "Epoch 21: val_auc did not improve from 0.55125\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - acc: 0.5961 - auc: 0.6323 - auprc: 0.6555 - loss: 0.6651 - prec: 0.6083 - rec: 0.6471 - val_acc: 0.5232 - val_auc: 0.5479 - val_auprc: 0.5491 - val_loss: 0.6925 - val_prec: 0.5625 - val_rec: 0.2739 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.6116 - auc: 0.6551 - auprc: 0.6996 - loss: 0.6563 - prec: 0.6522 - rec: 0.5951\n",
      "Epoch 22: val_auc did not improve from 0.55125\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5969 - auc: 0.6381 - auprc: 0.6619 - loss: 0.6632 - prec: 0.6272 - rec: 0.5719 - val_acc: 0.5210 - val_auc: 0.5403 - val_auprc: 0.5385 - val_loss: 0.6931 - val_prec: 0.5546 - val_rec: 0.2870 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5806 - auc: 0.6353 - auprc: 0.6627 - loss: 0.6630 - prec: 0.6052 - rec: 0.5540\n",
      "Epoch 23: val_auc did not improve from 0.55125\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5819 - auc: 0.6336 - auprc: 0.6570 - loss: 0.6637 - prec: 0.6137 - rec: 0.5490 - val_acc: 0.5430 - val_auc: 0.5384 - val_auprc: 0.5411 - val_loss: 0.6924 - val_prec: 0.5642 - val_rec: 0.4391 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5910 - auc: 0.6416 - auprc: 0.6705 - loss: 0.6605 - prec: 0.6022 - rec: 0.6347\n",
      "Epoch 24: val_auc did not improve from 0.55125\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - acc: 0.5879 - auc: 0.6315 - auprc: 0.6613 - loss: 0.6637 - prec: 0.6123 - rec: 0.5858 - val_acc: 0.5188 - val_auc: 0.5432 - val_auprc: 0.5435 - val_loss: 0.6929 - val_prec: 0.5492 - val_rec: 0.2913 - learning_rate: 1.2500e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5950 - auc: 0.6402 - auprc: 0.6809 - loss: 0.6602 - prec: 0.6090 - rec: 0.6032\n",
      "Epoch 25: val_auc did not improve from 0.55125\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5948 - auc: 0.6453 - auprc: 0.6780 - loss: 0.6591 - prec: 0.6162 - rec: 0.6046 - val_acc: 0.5143 - val_auc: 0.5411 - val_auprc: 0.5417 - val_loss: 0.6949 - val_prec: 0.5833 - val_rec: 0.1522 - learning_rate: 1.2500e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.6126 - auc: 0.6636 - auprc: 0.6894 - loss: 0.6547 - prec: 0.6402 - rec: 0.6188\n",
      "Epoch 26: val_auc did not improve from 0.55125\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5952 - auc: 0.6453 - auprc: 0.6762 - loss: 0.6590 - prec: 0.6165 - rec: 0.6054 - val_acc: 0.5276 - val_auc: 0.5443 - val_auprc: 0.5437 - val_loss: 0.6938 - val_prec: 0.6000 - val_rec: 0.2087 - learning_rate: 1.2500e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5937 - auc: 0.6320 - auprc: 0.6525 - loss: 0.6653 - prec: 0.6156 - rec: 0.5851\n",
      "Epoch 27: val_auc did not improve from 0.55125\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.5965 - auc: 0.6459 - auprc: 0.6744 - loss: 0.6585 - prec: 0.6245 - rec: 0.5801 - val_acc: 0.5188 - val_auc: 0.5416 - val_auprc: 0.5413 - val_loss: 0.6938 - val_prec: 0.5732 - val_rec: 0.2043 - learning_rate: 1.2500e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5903 - auc: 0.6391 - auprc: 0.6613 - loss: 0.6611 - prec: 0.6021 - rec: 0.5857\n",
      "Epoch 28: val_auc did not improve from 0.55125\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - acc: 0.5952 - auc: 0.6413 - auprc: 0.6651 - loss: 0.6603 - prec: 0.6209 - rec: 0.5874 - val_acc: 0.5166 - val_auc: 0.5430 - val_auprc: 0.5429 - val_loss: 0.6949 - val_prec: 0.5846 - val_rec: 0.1652 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "# === 10) Train ===\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    class_weight=cw  # NEU\n",
    ")\n",
    "\n",
    "\n",
    "# Trainingskurve speichern\n",
    "pd.DataFrame(history.history).to_csv(RUN_DIR / \"history.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c53ab91e-8441-47ad-9232-7d6146316881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === env_info & model_card (Reproduzierbarkeit/Doku) ===\n",
    "env_info = {\n",
    "    \"python\": sys.version,\n",
    "    \"tensorflow\": tf.__version__,\n",
    "    \"numpy\": np.__version__,\n",
    "    \"pandas\": pd.__version__,\n",
    "    \"seed\": SEED,\n",
    "    \"lookback\": LOOKBACK,\n",
    "    \"features\": [\"logret_1d\"],  # falls du später mehr nutzt, hier dynamisieren\n",
    "    \"batch\": BATCH,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"optimizer\": \"Adam(1e-3)\",\n",
    "    \"loss\": \"BinaryCrossentropy\",\n",
    "    \"metrics\": [\"acc\",\"auc\",\"auprc\",\"prec\",\"rec\"]\n",
    "}\n",
    "with open(RUN_DIR / \"env_info.json\", \"w\") as f:\n",
    "    json.dump(env_info, f, indent=2)\n",
    "\n",
    "with open(RUN_DIR / \"model_card.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\n",
    "        \"# LSTM-Klassifikator\\n\\n\"\n",
    "        f\"- Input: Window={LOOKBACK} x Features={env_info['features']}\\n\"\n",
    "        \"- Loss: Binary Cross-Entropy\\n\"\n",
    "        \"- Optimizer: Adam(1e-3)\\n\"\n",
    "        \"- Metrics: acc, auc, auprc, precision, recall\\n\"\n",
    "        f\"- class_weight: {cw}\\n\"\n",
    "        \"- Notes: label = 1 wenn close(t+H) > close(t) (log-return-basiert)\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2a055b6c-b605-4dd4-b1c9-060d2d961ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {\n",
      "  \"acc\": 0.46035242080688477,\n",
      "  \"auc\": 0.5008494853973389,\n",
      "  \"auprc\": 0.5273241996765137,\n",
      "  \"loss\": 0.7126410603523254,\n",
      "  \"prec\": 0.5,\n",
      "  \"rec\": 0.01224489789456129\n",
      "}\n",
      "\n",
      "Confusion matrix (test):\n",
      " [[206   3]\n",
      " [242   3]]\n",
      "\n",
      "Classification report (test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.460     0.986     0.627       209\n",
      "           1      0.500     0.012     0.024       245\n",
      "\n",
      "    accuracy                          0.460       454\n",
      "   macro avg      0.480     0.499     0.325       454\n",
      "weighted avg      0.482     0.460     0.302       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === 11) Evaluate & Berichte ===\n",
    "# Best Weights sind dank EarlyStopping bereits geladen\n",
    "test_metrics = model.evaluate(ds_test, return_dict=True, verbose=0)\n",
    "print(\"Test metrics:\", json.dumps(test_metrics, indent=2))\n",
    "\n",
    "# Schwellenwert 0.5 (später kalibrierbar)\n",
    "y_proba = model.predict(ds_test, verbose=0).ravel()\n",
    "y_pred  = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nConfusion matrix (test):\\n\", confusion_matrix(yte, y_pred))\n",
    "print(\"\\nClassification report (test):\\n\", classification_report(yte, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7f537297-0c99-490a-8713-acb51b6620fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Block3 quick] thr(val@maxMCC)=0.485 | AUROC val/test=0.547/0.498\n",
      "CM(test@thr):\n",
      " [[202   7]\n",
      " [241   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.456     0.967     0.620       209\n",
      "           1      0.364     0.016     0.031       245\n",
      "\n",
      "    accuracy                          0.454       454\n",
      "   macro avg      0.410     0.491     0.325       454\n",
      "weighted avg      0.406     0.454     0.302       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Val-basierte Schwelle (max MCC, Korridor) direkt in Block 3\n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "val_proba = model.predict(ds_val, verbose=0).ravel()\n",
    "\n",
    "def choose_threshold(y_true, y_prob, bounds=(0.2, 0.8)):\n",
    "    uniq = np.unique(y_prob); cand = np.r_[0.0, uniq, 1.0]\n",
    "    best_t, best_s = 0.5, -1\n",
    "    for t in cand:\n",
    "        yp = (y_prob >= t).astype(int)\n",
    "        pr = yp.mean()\n",
    "        if not (bounds[0] <= pr <= bounds[1]): \n",
    "            continue\n",
    "        s = matthews_corrcoef(y_true, yp)\n",
    "        if s > best_s: best_s, best_t = s, float(t)\n",
    "    return best_t\n",
    "\n",
    "thr = choose_threshold(yva, val_proba, bounds=(0.2,0.8))\n",
    "y_pred_thr = (y_proba >= thr).astype(int)\n",
    "\n",
    "print(f\"\\n[Block3 quick] thr(val@maxMCC)={thr:.3f} | AUROC val/test={roc_auc_score(yva, val_proba):.3f}/{roc_auc_score(yte, y_proba):.3f}\")\n",
    "print(\"CM(test@thr):\\n\", confusion_matrix(yte, y_pred_thr))\n",
    "print(classification_report(yte, y_pred_thr, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "95bc992f-6ae8-43b7-bda5-4138cfa99a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proba stats  (test): min= 0.3792177140712738 max= 0.5352762937545776 mean= 0.43799129128456116\n",
      "AUROC val/test: 0.547 / 0.498\n"
     ]
    }
   ],
   "source": [
    "# --- Diagnose der Probabilitäten ---\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"Proba stats  (test): min=\", float(y_proba.min()), \n",
    "      \"max=\", float(y_proba.max()), \"mean=\", float(y_proba.mean()))\n",
    "\n",
    "# AUC auf VAL & TEST (Ranking-Qualität, unabhängig vom Threshold)\n",
    "val_proba = model.predict(ds_val, verbose=0).ravel()\n",
    "print(\"AUROC val/test:\", \n",
    "      round(roc_auc_score(yva, val_proba), 3), \"/\", \n",
    "      round(roc_auc_score(yte, y_proba), 3))\n",
    "\n",
    "# Quick check: Ist das Signal invertiert?\n",
    "if roc_auc_score(yva, val_proba) < 0.5:\n",
    "    print(\"⚠️ AUROC < 0.5 auf VAL → Versuch: invertiere Scores (1-p)\")\n",
    "    y_proba_inverted = 1.0 - y_proba\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    y_pred_inv = (y_proba_inverted >= 0.5).astype(int)\n",
    "    print(\"Confusion (inv, thr=0.5):\\n\", confusion_matrix(yte, y_pred_inv))\n",
    "    print(\"Report (inv):\\n\", classification_report(yte, y_pred_inv, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "40b21880-6972-4be7-8000-3fe244cd2538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra test metrics: {\n",
      "  \"balanced_accuracy\": 0.4989454154867689,\n",
      "  \"mcc\": -0.009205617762249547,\n",
      "  \"auprc\": 0.5283307301859568\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# === Extra Test-Metriken ===\n",
    "bal_acc = balanced_accuracy_score(yte, y_pred)\n",
    "mcc = matthews_corrcoef(yte, y_pred)\n",
    "auprc_test = average_precision_score(yte, y_proba)  # probabilistische PR-Qualität\n",
    "\n",
    "extra = {\n",
    "    \"balanced_accuracy\": float(bal_acc),\n",
    "    \"mcc\": float(mcc),\n",
    "    \"auprc\": float(auprc_test)\n",
    "}\n",
    "print(\"Extra test metrics:\", json.dumps(extra, indent=2))\n",
    "\n",
    "# persistieren\n",
    "with open(RUN_DIR / \"extra_test_metrics.json\", \"w\") as f:\n",
    "    json.dump(extra, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "978a8ca1-2094-4e71-bce5-33df526f1e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Artefakte gespeichert in: ..\\results\\2025-10-03_00-36-36_lstm\n"
     ]
    }
   ],
   "source": [
    "# === 12) Artefakte sichern ===\n",
    "# Keras-Format (SavedModel) + Gewichte\n",
    "model.save(RUN_DIR / \"model.keras\")\n",
    "np.save(RUN_DIR / \"y_test.npy\", yte)\n",
    "np.save(RUN_DIR / \"y_proba.npy\", y_proba)\n",
    "with open(RUN_DIR / \"config.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"ticker\": TICKER, \"start\": START, \"end\": END, \"interval\": INTERVAL,\n",
    "        \"horizon\": HORIZON, \"lookback\": LOOKBACK, \"features\": FEATURES,\n",
    "        \"scaler\": \"StandardScaler\", \"seed\": SEED, \"batch\": BATCH, \"epochs\": EPOCHS\n",
    "    }, f, indent=2)\n",
    "print(f\"\\nArtefakte gespeichert in: {RUN_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c21f136-1586-402a-b44a-e1275cce874a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (finance-lstm)",
   "language": "python",
   "name": "finance-lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
