{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "362a40d2-85eb-4eb7-9305-75a83695cb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_DIR: ..\\results\\2025-10-02_22-01-04_lstm\n"
     ]
    }
   ],
   "source": [
    "import os, sys, json, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = os.path.abspath(\"..\")\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)\n",
    "\n",
    "with open(os.path.join(ROOT, \"config.json\"), \"r\") as f:\n",
    "    C = json.load(f)\n",
    "\n",
    "TICKER   = C[\"ticker\"]; START = C[\"start\"]; END = C[\"end\"]; INTERVAL = C[\"interval\"]\n",
    "HORIZON  = int(C[\"horizon\"]); LOOKBACK = int(C[\"lookback\"])\n",
    "BATCH    = int(C[\"batch\"]);   EPOCHS   = int(C[\"epochs\"])\n",
    "SEED     = int(C.get(\"seed\", 42))\n",
    "\n",
    "RESULTS_DIR = Path(C.get(\"results_dir\", \"../results\"))\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RUN_DIR   = RESULTS_DIR / time.strftime(\"%Y-%m-%d_%H-%M-%S_lstm\")\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)   # <- hinzufügen\n",
    "print(\"RUN_DIR:\", RUN_DIR)                   # optional\n",
    "\n",
    "TRAIN_CSV = f\"../data/{TICKER}_{INTERVAL}_{START}_{END}_cls_h{HORIZON}.csv\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44414e9d-0397-49fc-9c80-2841f2950d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_CSV, index_col=0, parse_dates=[0]).sort_index()\n",
    "\n",
    "exp = {\"open\",\"high\",\"low\",\"close\",\"volume\",\"logret_1d\",\"target\"}\n",
    "missing = exp - set(df.columns)\n",
    "assert not missing, f\"Fehlende Spalten: {missing}\"\n",
    "assert not df.index.has_duplicates\n",
    "assert (df[\"close\"] > 0).all()\n",
    "assert df.notna().all().all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07b91fc5-71ec-46b3-b625-f02038552a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3) Features / Ziel wählen ===\n",
    "FEATURES = [\"logret_1d\"]    # Start einfach; später gerne mehr Indikatoren\n",
    "TARGET   = \"target\"\n",
    "\n",
    "X = df[FEATURES].copy()\n",
    "y = df[TARGET].astype(int).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af24474a-6165-44f4-9243-a688d6372c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes → train 2403, val 515, test 516\n"
     ]
    }
   ],
   "source": [
    "# === 4) Chronologische Splits (70/15/15) ===\n",
    "n = len(df)\n",
    "n_train = int(n * 0.70)\n",
    "n_val   = int(n * 0.15)\n",
    "n_test  = n - n_train - n_val\n",
    "\n",
    "train_idx = slice(0, n_train)\n",
    "val_idx   = slice(n_train, n_train + n_val)\n",
    "test_idx  = slice(n_train + n_val, n)\n",
    "\n",
    "X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "X_val,   y_val   = X.iloc[val_idx],   y.iloc[val_idx]\n",
    "X_test,  y_test  = X.iloc[test_idx],  y.iloc[test_idx]\n",
    "\n",
    "print(f\"Split sizes → train {len(X_train)}, val {len(X_val)}, test {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e6af278-7df7-4bd2-beb7-ad8eea7e7bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\results\\\\2025-10-02_22-01-04_lstm\\\\scaler.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 5) Scaler nur auf TRAIN fitten ===\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_s = pd.DataFrame(scaler.fit_transform(X_train), index=X_train.index, columns=FEATURES)\n",
    "X_val_s   = pd.DataFrame(scaler.transform(X_val),       index=X_val.index,   columns=FEATURES)\n",
    "X_test_s  = pd.DataFrame(scaler.transform(X_test),      index=X_test.index,  columns=FEATURES)\n",
    "\n",
    "# Scaler speichern (für spätere Runs/Inference)\n",
    "import joblib, io\n",
    "joblib.dump(scaler, RUN_DIR / \"scaler.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de930d62-f80e-408a-9471-fcdbb3c2b9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: \n",
      "  train: (2344, 60, 1) (2344,) \n",
      "  val  : (456, 60, 1) (456,) \n",
      "  test : (457, 60, 1) (457,)\n"
     ]
    }
   ],
   "source": [
    "# === 6) Windowing: Sequenzen der Länge LOOKBACK → Label am Endzeitpunkt ===\n",
    "def make_windows(X_df: pd.DataFrame, y_ser: pd.Series, lookback: int):\n",
    "    X_values = X_df.values.astype(np.float32)\n",
    "    y_values = y_ser.values.astype(np.int32)\n",
    "    n = len(X_df)\n",
    "    xs, ys = [], []\n",
    "    for i in range(lookback-1, n):\n",
    "        xs.append(X_values[i - lookback + 1 : i + 1])  # inkl. i\n",
    "        ys.append(y_values[i])                          # Label für Zeitpunkt i (Up/Down für i->i+H)\n",
    "    return np.stack(xs, axis=0), np.array(ys)\n",
    "\n",
    "Xtr_win, ytr = make_windows(X_train_s, y_train, LOOKBACK)\n",
    "Xva_win, yva = make_windows(X_val_s,   y_val,   LOOKBACK)\n",
    "Xte_win, yte = make_windows(X_test_s,  y_test,  LOOKBACK)\n",
    "\n",
    "print(\"Shapes:\",\n",
    "      \"\\n  train:\", Xtr_win.shape, ytr.shape,\n",
    "      \"\\n  val  :\", Xva_win.shape, yva.shape,\n",
    "      \"\\n  test :\", Xte_win.shape, yte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a77b7452-9bcd-4b45-b92a-16a8e83f44ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7) tf.data Pipelines ===\n",
    "def to_ds(X, y, batch, shuffle):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(X), seed=SEED, reshuffle_each_iteration=True)\n",
    "    return ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_train = to_ds(Xtr_win, ytr, BATCH, shuffle=True)\n",
    "ds_val   = to_ds(Xva_win, yva, BATCH, shuffle=False)\n",
    "ds_test  = to_ds(Xte_win, yte, BATCH, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76d25d1b-8215-40c9-9b57-e469739b9fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m16,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,857</span> (116.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,857\u001b[0m (116.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,857</span> (116.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,857\u001b[0m (116.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 8) Modell definieren ===\n",
    "n_features = Xtr_win.shape[-1]\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(LOOKBACK, n_features)),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(32),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        keras.metrics.BinaryAccuracy(name=\"acc\"),\n",
    "        keras.metrics.AUC(name=\"auc\"),\n",
    "        keras.metrics.Precision(name=\"prec\"),\n",
    "        keras.metrics.Recall(name=\"rec\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "400bb060-c145-413b-a38e-9c4221173f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 9) Callbacks ===\n",
    "ckpt_path = RUN_DIR / \"best.keras\"\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(ckpt_path),\n",
    "        monitor=\"val_auc\",\n",
    "        mode=\"max\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1,\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_auc\", mode=\"max\", patience=10, restore_best_weights=True\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_auc\", mode=\"max\", factor=0.5, patience=5, verbose=1\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9ee003a-f770-44c4-8444-4b8096ee3434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.4998 - auc: 0.4799 - loss: 0.6935 - prec: 0.5180 - rec: 0.5683\n",
      "Epoch 1: val_auc improved from None to 0.48470, saving model to ..\\results\\2025-10-02_22-01-04_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - acc: 0.5107 - auc: 0.4910 - loss: 0.6929 - prec: 0.5205 - rec: 0.8280 - val_acc: 0.5088 - val_auc: 0.4847 - val_loss: 0.6940 - val_prec: 0.5088 - val_rec: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m33/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5069 - auc: 0.5235 - loss: 0.6930 - prec: 0.5059 - rec: 0.9767\n",
      "Epoch 2: val_auc did not improve from 0.48470\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5205 - auc: 0.5190 - loss: 0.6920 - prec: 0.5236 - rec: 0.9324 - val_acc: 0.4978 - val_auc: 0.4786 - val_loss: 0.6967 - val_prec: 0.5034 - val_rec: 0.9483 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5395 - auc: 0.5004 - loss: 0.6906 - prec: 0.5415 - rec: 0.9815\n",
      "Epoch 3: val_auc did not improve from 0.48470\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5269 - auc: 0.5017 - loss: 0.6926 - prec: 0.5260 - rec: 0.9715 - val_acc: 0.4912 - val_auc: 0.4778 - val_loss: 0.6941 - val_prec: 0.5000 - val_rec: 0.8103 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5518 - auc: 0.5438 - loss: 0.6892 - prec: 0.5577 - rec: 0.8505\n",
      "Epoch 4: val_auc did not improve from 0.48470\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5273 - auc: 0.5141 - loss: 0.6919 - prec: 0.5309 - rec: 0.8321 - val_acc: 0.5044 - val_auc: 0.4795 - val_loss: 0.6942 - val_prec: 0.5086 - val_rec: 0.7629 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5327 - auc: 0.5487 - loss: 0.6899 - prec: 0.5349 - rec: 0.8177\n",
      "Epoch 5: val_auc improved from 0.48470 to 0.49446, saving model to ..\\results\\2025-10-02_22-01-04_lstm\\best.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5213 - auc: 0.5202 - loss: 0.6915 - prec: 0.5268 - rec: 0.8411 - val_acc: 0.5044 - val_auc: 0.4945 - val_loss: 0.6941 - val_prec: 0.5066 - val_rec: 0.9914 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m33/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5294 - auc: 0.5229 - loss: 0.6913 - prec: 0.5255 - rec: 0.9638\n",
      "Epoch 6: val_auc did not improve from 0.49446\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5299 - auc: 0.5188 - loss: 0.6913 - prec: 0.5288 - rec: 0.9340 - val_acc: 0.5000 - val_auc: 0.4849 - val_loss: 0.6954 - val_prec: 0.5055 - val_rec: 0.7931 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m33/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5343 - auc: 0.5301 - loss: 0.6903 - prec: 0.5342 - rec: 0.8885\n",
      "Epoch 7: val_auc did not improve from 0.49446\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5252 - auc: 0.5189 - loss: 0.6912 - prec: 0.5287 - rec: 0.8557 - val_acc: 0.5110 - val_auc: 0.4804 - val_loss: 0.6953 - val_prec: 0.5114 - val_rec: 0.8707 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m33/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5326 - auc: 0.5319 - loss: 0.6905 - prec: 0.5303 - rec: 0.9427\n",
      "Epoch 8: val_auc did not improve from 0.49446\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5380 - auc: 0.5339 - loss: 0.6902 - prec: 0.5333 - rec: 0.9397 - val_acc: 0.4978 - val_auc: 0.4812 - val_loss: 0.6958 - val_prec: 0.5042 - val_rec: 0.7845 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m32/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5395 - auc: 0.5393 - loss: 0.6890 - prec: 0.5407 - rec: 0.8627\n",
      "Epoch 9: val_auc did not improve from 0.49446\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5282 - auc: 0.5305 - loss: 0.6907 - prec: 0.5333 - rec: 0.7897 - val_acc: 0.5044 - val_auc: 0.4931 - val_loss: 0.6954 - val_prec: 0.5091 - val_rec: 0.7198 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5452 - auc: 0.5464 - loss: 0.6889 - prec: 0.5402 - rec: 0.8946\n",
      "Epoch 10: val_auc did not improve from 0.49446\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5397 - auc: 0.5375 - loss: 0.6896 - prec: 0.5356 - rec: 0.9071 - val_acc: 0.5132 - val_auc: 0.4724 - val_loss: 0.6971 - val_prec: 0.5145 - val_rec: 0.7672 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5434 - auc: 0.5562 - loss: 0.6875 - prec: 0.5423 - rec: 0.8658\n",
      "Epoch 11: val_auc did not improve from 0.49446\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5346 - auc: 0.5467 - loss: 0.6886 - prec: 0.5357 - rec: 0.8321 - val_acc: 0.5088 - val_auc: 0.4703 - val_loss: 0.6974 - val_prec: 0.5118 - val_rec: 0.7457 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5553 - auc: 0.5545 - loss: 0.6858 - prec: 0.5501 - rec: 0.8774\n",
      "Epoch 12: val_auc did not improve from 0.49446\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5380 - auc: 0.5344 - loss: 0.6895 - prec: 0.5365 - rec: 0.8615 - val_acc: 0.4956 - val_auc: 0.4874 - val_loss: 0.6962 - val_prec: 0.5029 - val_rec: 0.7500 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m32/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5460 - auc: 0.5358 - loss: 0.6880 - prec: 0.5448 - rec: 0.8956\n",
      "Epoch 13: val_auc did not improve from 0.49446\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5392 - auc: 0.5489 - loss: 0.6887 - prec: 0.5355 - rec: 0.9030 - val_acc: 0.4868 - val_auc: 0.4655 - val_loss: 0.6979 - val_prec: 0.4973 - val_rec: 0.7845 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5474 - auc: 0.5328 - loss: 0.6871 - prec: 0.5516 - rec: 0.8534\n",
      "Epoch 14: val_auc did not improve from 0.49446\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5418 - auc: 0.5499 - loss: 0.6877 - prec: 0.5402 - rec: 0.8370 - val_acc: 0.5219 - val_auc: 0.4675 - val_loss: 0.6994 - val_prec: 0.5205 - val_rec: 0.7672 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5437 - auc: 0.5711 - loss: 0.6859 - prec: 0.5389 - rec: 0.8258\n",
      "Epoch 15: val_auc did not improve from 0.49446\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5397 - auc: 0.5568 - loss: 0.6867 - prec: 0.5398 - rec: 0.8183 - val_acc: 0.4978 - val_auc: 0.4711 - val_loss: 0.6987 - val_prec: 0.5042 - val_rec: 0.7672 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# === 10) Train ===\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Trainingskurve speichern\n",
    "pd.DataFrame(history.history).to_csv(RUN_DIR / \"history.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a055b6c-b605-4dd4-b1c9-060d2d961ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {\n",
      "  \"acc\": 0.5339168310165405,\n",
      "  \"auc\": 0.513331413269043,\n",
      "  \"loss\": 0.6904076337814331,\n",
      "  \"prec\": 0.5379464030265808,\n",
      "  \"rec\": 0.9757084846496582\n",
      "}\n",
      "\n",
      "Confusion matrix (test):\n",
      " [[  3 207]\n",
      " [  6 241]]\n",
      "\n",
      "Classification report (test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.333     0.014     0.027       210\n",
      "           1      0.538     0.976     0.694       247\n",
      "\n",
      "    accuracy                          0.534       457\n",
      "   macro avg      0.436     0.495     0.360       457\n",
      "weighted avg      0.444     0.534     0.387       457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === 11) Evaluate & Berichte ===\n",
    "# Best Weights sind dank EarlyStopping bereits geladen\n",
    "test_metrics = model.evaluate(ds_test, return_dict=True, verbose=0)\n",
    "print(\"Test metrics:\", json.dumps(test_metrics, indent=2))\n",
    "\n",
    "# Schwellenwert 0.5 (später kalibrierbar)\n",
    "y_proba = model.predict(ds_test, verbose=0).ravel()\n",
    "y_pred  = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nConfusion matrix (test):\\n\", confusion_matrix(yte, y_pred))\n",
    "print(\"\\nClassification report (test):\\n\", classification_report(yte, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "978a8ca1-2094-4e71-bce5-33df526f1e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Artefakte gespeichert in: ..\\results\\2025-10-02_22-01-04_lstm\n"
     ]
    }
   ],
   "source": [
    "# === 12) Artefakte sichern ===\n",
    "# Keras-Format (SavedModel) + Gewichte\n",
    "model.save(RUN_DIR / \"model.keras\")\n",
    "np.save(RUN_DIR / \"y_test.npy\", yte)\n",
    "np.save(RUN_DIR / \"y_proba.npy\", y_proba)\n",
    "with open(RUN_DIR / \"config.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"ticker\": TICKER, \"start\": START, \"end\": END, \"interval\": INTERVAL,\n",
    "        \"horizon\": HORIZON, \"lookback\": LOOKBACK, \"features\": FEATURES,\n",
    "        \"scaler\": \"StandardScaler\", \"seed\": SEED, \"batch\": BATCH, \"epochs\": EPOCHS\n",
    "    }, f, indent=2)\n",
    "print(f\"\\nArtefakte gespeichert in: {RUN_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c21f136-1586-402a-b44a-e1275cce874a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (finance-lstm)",
   "language": "python",
   "name": "finance-lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
