{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0815ad64-f59a-4d0c-931c-066a8ffbbf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 07_report.py  —  Konsolidierter Abschlussreport (auto RUN_DIR)\n",
    "# - wählt automatisch den neuesten passenden *_lstm Run (Lookback/H/eps)\n",
    "# - liest evaluation.json (+ optional cost_sensitivity.csv von Block 6)\n",
    "# - fasst Metriken & Backtests zusammen\n",
    "# - schreibt: REPORT_block7.md, REPORT_block7_kpis.json, kpis_block7.csv (optional)\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db17a3bd-70e4-4b31-967b-b18ec77373a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, yaml, re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aabe6ed9-b8f0-4843-9051-3352546c50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- kleine Helfer ----------\n",
    "def jread(p: Path):\n",
    "    with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def latest_lstm_run(results_dir: Path,\n",
    "                    lookback: int = None,\n",
    "                    horizon: int = None,\n",
    "                    eps_mode: str = None,\n",
    "                    epsilon: float = None,\n",
    "                    strict: bool = False) -> Path | None:\n",
    "    runs = sorted(results_dir.glob(\"*_lstm\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    if not runs:\n",
    "        return None\n",
    "\n",
    "    def matches(run: Path) -> bool:\n",
    "        try:\n",
    "            cfg = jread(run / \"config.json\")\n",
    "        except Exception:\n",
    "            return False\n",
    "        ok_lb = (lookback is None) or (int(cfg.get(\"lookback\", -1)) == lookback)\n",
    "        tc = str(cfg.get(\"train_csv\", \"\"))\n",
    "        mH = re.search(r\"_cls_h(\\d+)_\", tc)\n",
    "        mE = re.search(r\"_(abs|rel)([\\dp]+)\\.csv$\", tc)\n",
    "        ok_h = True if horizon is None else (int(cfg.get(\"horizon\", -1)) == horizon or (mH and int(mH.group(1)) == horizon))\n",
    "        ok_m = True if eps_mode is None else ((mE and mE.group(1) == eps_mode))\n",
    "        ok_e = True\n",
    "        if epsilon is not None:\n",
    "            if mE:\n",
    "                ok_e = float(mE.group(2).replace(\"p\",\".\")) == float(epsilon)\n",
    "            else:\n",
    "                ok_e = float(cfg.get(\"epsilon\", 1e9)) == float(epsilon)\n",
    "        return ok_lb and ok_h and ok_m and ok_e\n",
    "\n",
    "    matches_list = [r for r in runs if matches(r)]\n",
    "    if matches_list:\n",
    "        return matches_list[0]\n",
    "    return None if strict else runs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2829a180-c092-4e26-9e97-b2be4b71c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Root-Config & Label auflösen ----------\n",
    "ROOT = Path(\"..\").resolve()\n",
    "with open(ROOT / \"config.json\", \"r\") as f:\n",
    "    C = json.load(f)\n",
    "\n",
    "RESULTS_DIR = Path(C.get(\"results_dir\", \"../results\")).resolve()\n",
    "LOOKBACK    = int(C[\"lookback\"])\n",
    "FEATURESET  = C.get(\"featureset\", \"v2\")\n",
    "\n",
    "# Label primär aus YAML lesen (Block 2 schreibt das hinein)\n",
    "HORIZON = MODE = EPS = None\n",
    "yml = ROOT / f\"data/features_{FEATURESET}.yml\"\n",
    "if yml.exists():\n",
    "    meta = yaml.safe_load(open(yml, \"r\")) or {}\n",
    "    lab = meta.get(\"label\", {})\n",
    "    HORIZON = int(lab.get(\"horizon\", 0)) or None\n",
    "    MODE    = str(lab.get(\"mode\", \"\")) or None\n",
    "    EPS     = float(lab.get(\"epsilon\", 0.0)) or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b898427f-16bc-44dd-ba5e-5f2abd283aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_DIR -> C:\\Users\\jacin\\finance-lstm\\results\\2025-10-22_12-14-18_lstm\n"
     ]
    }
   ],
   "source": [
    "# ---------- RUN_DIR ermitteln ----------\n",
    "run_override = os.getenv(\"RUN_DIR\", \"\").strip() or None\n",
    "if run_override:\n",
    "    RUN_DIR = Path(run_override).resolve()\n",
    "else:\n",
    "    RUN_DIR = latest_lstm_run(RESULTS_DIR, lookback=LOOKBACK, horizon=HORIZON, eps_mode=MODE, epsilon=EPS, strict=False)\n",
    "\n",
    "if RUN_DIR is None or not RUN_DIR.exists():\n",
    "    raise SystemExit(\"Kein *_lstm Run gefunden. Bitte Block 3/4/6 vorher einmal ausführen.\")\n",
    "\n",
    "print(\"RUN_DIR ->\", RUN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23f9e4fd-dafa-468d-8049-f2437e2e2cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Artefakte einlesen ----------\n",
    "ev_path = RUN_DIR / \"evaluation.json\"\n",
    "if not ev_path.exists():\n",
    "    raise SystemExit(f\"evaluation.json fehlt in {RUN_DIR} (Block 4/6).\")\n",
    "\n",
    "ev    = jread(ev_path)\n",
    "cfg   = ev.get(\"config\", {})\n",
    "metrics = (ev.get(\"metrics\", {}) or {}).get(\"test\", {})\n",
    "thr_sel = ev.get(\"threshold_selection\", {})\n",
    "calib   = ev.get(\"calibration\", {})\n",
    "backtest_gross = ev.get(\"backtest\", {})\n",
    "\n",
    "# Falls YAML nicht gesetzt war, Label jetzt sicher aus evaluation übernehmen\n",
    "if HORIZON is None:\n",
    "    HORIZON = int(((ev.get(\"label_resolved_from\") or {}).get(\"horizon\")) or cfg.get(\"horizon\"))\n",
    "if MODE is None:\n",
    "    MODE = (ev.get(\"label_resolved_from\") or {}).get(\"mode\") or cfg.get(\"epsilon_mode\")\n",
    "if EPS is None:\n",
    "    EPS = float((ev.get(\"label_resolved_from\") or {}).get(\"epsilon\") or cfg.get(\"epsilon\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0407107f-a03e-4891-856e-c16726338a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Kosten-Sensitivität laden ----------\n",
    "sens_path = RUN_DIR / \"cost_sensitivity.csv\"\n",
    "sens_df = pd.read_csv(sens_path) if sens_path.exists() else None\n",
    "\n",
    "MAIN_RT = 15.0\n",
    "MAIN_SLIP_PER_LEG = 2.0\n",
    "\n",
    "cost_pick = {}\n",
    "if sens_df is not None and len(sens_df):\n",
    "    # CHANGE (Pflicht): KPI nur aus Entry@t+1 wählen\n",
    "    df_t1_exact = sens_df[sens_df[\"model\"] == \"Entry@t+1\"]                          # exakter Name\n",
    "    df_t1_prefix = sens_df[sens_df[\"model\"].astype(str).str.startswith(\"Entry@t+1\")]# fallback (z.B. \"Entry@t+1 (No-Overlap)\")\n",
    "    df_t1 = df_t1_exact if len(df_t1_exact) else df_t1_prefix\n",
    "\n",
    "    if not len(df_t1):\n",
    "        # äußerster Fallback: gesamte Sensitivität verwenden (sollte nicht nötig sein)\n",
    "        df_t1 = sens_df.copy()\n",
    "\n",
    "    df_t1[\"rt_diff\"] = (df_t1[\"roundtrip_bps\"] - MAIN_RT).abs()\n",
    "    row = df_t1.sort_values([\"rt_diff\", \"roundtrip_bps\"]).iloc[0].to_dict()\n",
    "    cost_pick = dict(\n",
    "        model=row[\"model\"], roundtrip_bps=float(row[\"roundtrip_bps\"]),\n",
    "        trades=int(row.get(\"trades\", 0)), exposure=float(row.get(\"exposure\", np.nan)),\n",
    "        turnover=float(row.get(\"turnover\", np.nan)),\n",
    "        CAGR=float(row[\"CAGR\"]), Sharpe=float(row[\"Sharpe\"]), MaxDD=float(row[\"MaxDD\"]),\n",
    "        final_equity=float(row[\"final_equity\"]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69024c17-9f6c-4017-97de-5b7c461aff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Baselines (Empfehlung): Always-Up, LogReg, MACD -------------------\n",
    "# Wir rekonstruieren die Splits, damit LogReg & MACD gegen denselben Test laufen\n",
    "TRAIN_CSV = Path(cfg.get(\"train_csv\", \"\"))\n",
    "features_list = cfg.get(\"features\", None)\n",
    "if not features_list:\n",
    "    # Fallback: YAML\n",
    "    yml = ROOT / f\"data/features_{FEATURESET}.yml\"\n",
    "    if yml.exists():\n",
    "        meta = yaml.safe_load(open(yml, \"r\")) or {}\n",
    "        features_list = meta.get(\"features\", [])\n",
    "df_all = pd.read_csv(TRAIN_CSV, index_col=0, parse_dates=True).sort_index()\n",
    "X_all = df_all[features_list].copy()\n",
    "y_all = df_all[\"target\"].astype(int).copy()\n",
    "\n",
    "n = len(df_all)\n",
    "n_train = int(n * 0.70)\n",
    "n_val   = int(n * 0.15)\n",
    "n_test  = n - n_train - n_val\n",
    "\n",
    "X_train, y_train = X_all.iloc[:n_train],              y_all.iloc[:n_train]\n",
    "X_val,   y_val   = X_all.iloc[n_train:n_train+n_val], y_all.iloc[n_train:n_train+n_val]\n",
    "X_test,  y_test  = X_all.iloc[n_train+n_val:],        y_all.iloc[n_train+n_val:]\n",
    "\n",
    "# Window-Ende-Ausrichtung (wie im Netz)\n",
    "LB = int(cfg.get(\"lookback\", LOOKBACK))\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "Xtr_s = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "Xva_s = pd.DataFrame(scaler.transform(X_val),   index=X_val.index,   columns=X_val.columns)\n",
    "Xte_s = pd.DataFrame(scaler.transform(X_test),  index=X_test.index,  columns=X_test.columns)\n",
    "\n",
    "tail = slice(LB-1, None)\n",
    "ytr_tail, yva_tail, yte_tail = y_train.iloc[tail], y_val.iloc[tail], y_test.iloc[tail]\n",
    "Xtr_tail, Xva_tail, Xte_tail = Xtr_s.iloc[tail],   Xva_s.iloc[tail],   Xte_s.iloc[tail]\n",
    "\n",
    "# Always-Up baseline\n",
    "pos_rate_test = float(yte_tail.mean())\n",
    "auprc_always_up = pos_rate_test   # PR-AUC der trivialen Positiv-Baseline\n",
    "\n",
    "# LogReg baseline neu fitten (wie in Block 3, nur für den Report)\n",
    "logit = LogisticRegression(max_iter=200)\n",
    "logit.fit(Xtr_tail, ytr_tail)\n",
    "proba_lr = logit.predict_proba(Xte_tail)[:,1]\n",
    "auprc_lr = float(average_precision_score(yte_tail, proba_lr))\n",
    "\n",
    "# Simple MACD-Regel als Score (roh: macd_diff auf Test-Tail)\n",
    "macd_diff = df_all.loc[Xte_tail.index, \"macd_diff\"].astype(float)\n",
    "# falls fehlend, setze Null\n",
    "if macd_diff.isna().any():\n",
    "    macd_diff = macd_diff.fillna(0.0)\n",
    "auprc_macd = float(average_precision_score(yte_tail, macd_diff.values))\n",
    "\n",
    "baselines_tbl = pd.DataFrame([\n",
    "    {\"baseline\": \"Always-Up\", \"auprc\": auprc_always_up, \"pos_rate\": pos_rate_test,\n",
    "     \"auprc_over_posrate\": (auprc_always_up / max(pos_rate_test, 1e-12))},\n",
    "    {\"baseline\": \"Logistic Regression\", \"auprc\": auprc_lr, \"pos_rate\": pos_rate_test,\n",
    "     \"auprc_over_posrate\": (auprc_lr / max(pos_rate_test, 1e-12))},\n",
    "    {\"baseline\": \"Simple MACD (macd_diff score)\", \"auprc\": auprc_macd, \"pos_rate\": pos_rate_test,\n",
    "     \"auprc_over_posrate\": (auprc_macd / max(pos_rate_test, 1e-12))}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a3d6ad-a1c5-4a7e-83d1-bf5de33dc062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- KPIs zusammensetzen ----------\n",
    "kpis = {\n",
    "    \"run_dir\": str(RUN_DIR),\n",
    "    \"generated_utc\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
    "    \"data\": {\n",
    "        \"ticker\": cfg.get(\"ticker\"),\n",
    "        \"interval\": cfg.get(\"interval\"),\n",
    "        \"period\": [cfg.get(\"start\"), cfg.get(\"end\")],\n",
    "        \"horizon\": cfg.get(\"horizon\"),\n",
    "        \"lookback\": cfg.get(\"lookback\"),\n",
    "        \"featureset\": cfg.get(\"featureset\"),\n",
    "        \"features_used\": ev.get(\"features_used\"),\n",
    "    },\n",
    "    \"label\": ev.get(\"label_resolved_from\"),\n",
    "    \"calibration\": {\n",
    "        \"chosen\": calib.get(\"chosen\"),\n",
    "        \"val_brier\": calib.get(\"val_brier\"),\n",
    "        \"test_brier\": calib.get(\"test_brier\"),\n",
    "        # CHANGE: explizite Textnotiz zur Kalibrierungsentscheidung\n",
    "        \"note\": \"Kalibrationsentscheidung ausschließlich auf Validation; Test nur zur Berichterstattung.\"\n",
    "    },\n",
    "    \"threshold\": {\n",
    "        \"strategy\": thr_sel.get(\"strategy\"),\n",
    "        \"threshold\": thr_sel.get(\"threshold\"),\n",
    "        \"val_mcc\": thr_sel.get(\"val_mcc\"),\n",
    "        \"test_pred_pos_rate\": thr_sel.get(\"test_pred_pos_rate\"),\n",
    "    },\n",
    "    \"classification_test\": {\n",
    "        \"roc_auc\": metrics.get(\"roc_auc\"),\n",
    "        \"auprc\": metrics.get(\"auprc\"),\n",
    "        \"brier\": metrics.get(\"brier\"),\n",
    "        \"balanced_accuracy\": metrics.get(\"balanced_accuracy\"),\n",
    "        \"mcc\": metrics.get(\"mcc\"),\n",
    "        \"confusion_matrix\": metrics.get(\"confusion_matrix\"),\n",
    "    },\n",
    "    \"backtest_gross\": backtest_gross,     # ohne Kosten (Block 4)\n",
    "    \"backtest_cost_pick\": cost_pick,      # netto Auswahl aus Block 6 (T+1-only)\n",
    "    \"baselines\": baselines_tbl.to_dict(orient=\"records\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e11499-04f4-45e6-9659-437cd867ed45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ REPORT geschrieben → C:\\Users\\jacin\\finance-lstm\\results\\2025-10-22_12-14-18_lstm\\REPORT_block7.md\n",
      "✓ KPIs JSON → C:\\Users\\jacin\\finance-lstm\\results\\2025-10-22_12-14-18_lstm\\REPORT_block7_kpis.json\n",
      "✓ KPIs CSV → C:\\Users\\jacin\\finance-lstm\\results\\2025-10-22_12-14-18_lstm\\kpis_block7.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------- Markdown-Report schreiben ----------\n",
    "fig_dir = RUN_DIR / \"figures\"\n",
    "figs = {\n",
    "    \"roc\": fig_dir / \"roc_test.png\",\n",
    "    \"pr\":  fig_dir / \"pr_test.png\",\n",
    "    \"calib\": fig_dir / \"calibration_test.png\",\n",
    "    \"cm\":   fig_dir / \"cm_test.png\",\n",
    "    \"proba\": fig_dir / \"proba_hist_raw_vs_used.png\",\n",
    "    \"equity_gross\": fig_dir / \"equity_curves_t_vs_t1.png\",\n",
    "    \"equity_cost\":  fig_dir / \"equity_costed.png\",\n",
    "}\n",
    "\n",
    "def _rel(p: Path) -> str:\n",
    "    return str(p.relative_to(RUN_DIR)) if p.exists() else str(p)\n",
    "\n",
    "report_md = RUN_DIR / \"REPORT_block7.md\"\n",
    "lines = []\n",
    "lines.append(f\"# Block 7 – Abschluss-Report\\n\")\n",
    "lines.append(f\"- **Run-Ordner:** `{RUN_DIR.name}`\")\n",
    "lines.append(f\"- **Erstellt (UTC):** {kpis['generated_utc']}\")\n",
    "lines.append(f\"- **Ticker/Intervall:** {kpis['data']['ticker']} / {kpis['data']['interval']}\")\n",
    "lines.append(f\"- **Zeitraum:** {kpis['data']['period'][0]} → {kpis['data']['period'][1]}\")\n",
    "lines.append(f\"- **Horizon/Lookback:** H={kpis['data']['horizon']} / LB={kpis['data']['lookback']}\")\n",
    "lines.append(f\"- **Featureset:** {kpis['data']['featureset']} → {', '.join(kpis['data']['features_used'])}\\n\")\n",
    "\n",
    "# Klassif.-Metriken\n",
    "m = kpis[\"classification_test\"]\n",
    "lines.append(\"## Test-Metriken\")\n",
    "lines.append(f\"- AUROC: **{m['roc_auc']:.3f}**, AUPRC: **{m['auprc']:.3f}** (Random-Baseline = Positivrate), Brier: **{m['brier']:.3f}**\")\n",
    "lines.append(f\"- Balanced Acc: **{m['balanced_accuracy']:.3f}**, MCC: **{m['mcc']:.3f}**\\n\")\n",
    "lines.append(f\"![ROC]({_rel(figs['roc'])})  \\n![PR]({_rel(figs['pr'])})\\n\")\n",
    "lines.append(f\"![Calibration]({_rel(figs['calib'])})  \\n![Confusion]({_rel(figs['cm'])})  \\n![Probas]({_rel(figs['proba'])})\\n\")\n",
    "\n",
    "# Kalibration – klarer Satz (Pflicht)\n",
    "lines.append(\"> **Kalibration:** Entscheidung ausschließlich auf der Validation; der Test-Split dient nur der Berichterstattung.\\n\")\n",
    "\n",
    "# Backtests\n",
    "lines.append(\"## Backtests\")\n",
    "bg = kpis[\"backtest_gross\"]\n",
    "if bg:\n",
    "    t  = bg.get(\"strategy_t\", {})\n",
    "    t1 = bg.get(\"strategy_t1\", {})\n",
    "    bh = bg.get(\"buy_hold\", {})\n",
    "    lines.append(f\"- **Ohne Kosten** – Entry@t: CAGR {t.get('CAGR'):.3f}, Sharpe {t.get('Sharpe'):.3f}, \"\n",
    "                 f\"Equity {t.get('final_equity'):.3f} *(Referenz/Upper bound, nicht handelbar)*;  \"\n",
    "                 f\"Entry@t+1: CAGR {t1.get('CAGR'):.3f}, Sharpe {t1.get('Sharpe'):.3f}, Equity {t1.get('final_equity'):.3f};  \"\n",
    "                 f\"Buy&Hold: CAGR {bh.get('CAGR'):.3f}, Equity {bh.get('final_equity'):.3f}.\")\n",
    "    lines.append(f\"![Equity gross]({_rel(figs['equity_gross'])})\\n\")\n",
    "\n",
    "cp = kpis[\"backtest_cost_pick\"]\n",
    "lines.append(\"## Kosten-KPI (realistisch, T+1)\")\n",
    "if cp:\n",
    "    lines.append(f\"- Gewählt: **{cp['model']}** bei **{cp['roundtrip_bps']:.1f} bps** (≈ Main {MAIN_RT:.0f} bps); \"\n",
    "                 f\"Trades={cp.get('trades','?')}, Exposure={cp.get('exposure',float('nan')):.3f}, \"\n",
    "                 f\"Turnover={cp.get('turnover',float('nan')):.1f}, CAGR={cp['CAGR']:.3f}, \"\n",
    "                 f\"Sharpe={cp['Sharpe']:.3f}, MaxDD={cp['MaxDD']:.3f}, Equity={cp['final_equity']:.3f}.\")\n",
    "    lines.append(f\"![Equity net]({_rel(figs['equity_cost'])})\\n\")\n",
    "else:\n",
    "    lines.append(\"- **Hinweis:** Keine `cost_sensitivity.csv` gefunden – Block 6 (Kosten-Backtest) noch nicht gelaufen.\\n\")\n",
    "\n",
    "# Baselines-Tabelle (Empfehlung)\n",
    "lines.append(\"## Baselines (PR-AUC relativ zur Positivrate)\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"| Baseline | PR-AUC | Positivrate | PR-AUC / Positivrate |\")\n",
    "lines.append(\"|---|---:|---:|---:|\")\n",
    "for r in kpis[\"baselines\"]:\n",
    "    lines.append(f\"| {r['baseline']} | {r['auprc']:.3f} | {r['pos_rate']:.3f} | {r['auprc_over_posrate']:.2f} |\")\n",
    "lines.append(\"\")\n",
    "\n",
    "# Limitations & Negativresultate (Empfehlung)\n",
    "lines.append(\"## Limitations & Negativresultate\")\n",
    "lines.append(\"- **ε-Sensitivität:** Ergebnisse hängen vom Label-Threshold ε ab; Sweeps zeigen teils deutliche Variation.\")\n",
    "lines.append(\"- **Schwacher MCC in WFCV:** Die walk-forward Cross-Validation ergab niedrige bis instabile MCC-Werte; Ranking-Fähigkeit ist begrenzt.\")\n",
    "lines.append(\"- **Regimewechsel:** Einmodell-Training über lange Zeiträume ist anfällig für Regimewechsel (Volatilität, Makro, Marktstruktur).\")\n",
    "lines.append(\"- **Single-Asset-Bias:** Ergebnisse basieren auf einem Asset/Ticker (AAPL); Generalisierbarkeit ist nicht gezeigt.\\n\")\n",
    "\n",
    "report_md.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "print(\"✓ REPORT geschrieben →\", report_md)\n",
    "\n",
    "# zusätzlich KPIs als JSON\n",
    "(RUN_DIR / \"REPORT_block7_kpis.json\").write_text(json.dumps(kpis, indent=2), encoding=\"utf-8\")\n",
    "print(\"✓ KPIs JSON →\", RUN_DIR / \"REPORT_block7_kpis.json\")\n",
    "\n",
    "# optional: CSV mit Kern-KPIs\n",
    "try:\n",
    "    kpi_rows = {\n",
    "        \"roc_auc\": metrics.get(\"roc_auc\"), \"auprc\": metrics.get(\"auprc\"), \"brier\": metrics.get(\"brier\"),\n",
    "        \"bal_acc\": metrics.get(\"balanced_accuracy\"), \"mcc\": metrics.get(\"mcc\"),\n",
    "        \"cost_model\": cp.get(\"model\") if cp else None,\n",
    "        \"cost_rt_bps\": cp.get(\"roundtrip_bps\") if cp else None,\n",
    "        \"cost_CAGR\": cp.get(\"CAGR\") if cp else None,\n",
    "        \"cost_Sharpe\": cp.get(\"Sharpe\") if cp else None,\n",
    "        \"cost_MaxDD\": cp.get(\"MaxDD\") if cp else None,\n",
    "        \"cost_Equity\": cp.get(\"final_equity\") if cp else None\n",
    "    }\n",
    "    pd.DataFrame([kpi_rows]).to_csv(RUN_DIR / \"kpis_block7.csv\", index=False)\n",
    "    print(\"✓ KPIs CSV →\", RUN_DIR / \"kpis_block7.csv\")\n",
    "except Exception as e:\n",
    "    print(\"[WARN] KPIs CSV nicht geschrieben:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414d0770-3370-4319-92da-a44b86ada7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (finance-lstm)",
   "language": "python",
   "name": "finance-lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
