{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5df2c55f-8949-47a2-94b9-bb1bc25587a1",
   "metadata": {},
   "source": [
    "# -----------------------------------------\n",
    "# Block 4: Threshold-Tuning, Evaluation, Backtest & Plots\n",
    "# -----------------------------------------\n",
    "# Lädt die Artefakte aus dem letzten RUN_DIR, rekonstruiert\n",
    "# Val/Test-Splits, wählt einen optimalen Schwellenwert auf Val\n",
    "# (max. F1), evaluiert auf Test, erstellt Plots und einfachen Backtest.\n",
    "# -----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c69ddd0-9c11-473b-a3c9-56496d3485ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_DIR: ..\\results\\2025-10-18_16-13-23_lstm\n"
     ]
    }
   ],
   "source": [
    "# --- Imports & Setup ---\n",
    "import os, sys, json, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score,\n",
    "    classification_report, confusion_matrix, brier_score_loss,\n",
    "    balanced_accuracy_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.calibration import calibration_curve, IsotonicRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib, yaml\n",
    "\n",
    "ROOT = os.path.abspath(\"..\")\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)\n",
    "\n",
    "with open(os.path.join(ROOT, \"config.json\"), \"r\") as f:\n",
    "    C = json.load(f)\n",
    "\n",
    "TICKER, START, END, INTERVAL = C[\"ticker\"], C[\"start\"], C[\"end\"], C[\"interval\"]\n",
    "HORIZON  = int(C[\"horizon\"])\n",
    "LOOKBACK = int(C[\"lookback\"])\n",
    "BATCH    = int(C[\"batch\"]);   EPOCHS = int(C[\"epochs\"])\n",
    "SEED     = int(C.get(\"seed\", 42))\n",
    "FEATURESET = C.get(\"featureset\", \"v2\")\n",
    "EPS_MODE   = C.get(\"epsilon_mode\", \"abs\")\n",
    "EPSILON    = float(C.get(\"epsilon\", 0.001))\n",
    "\n",
    "np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "RESULTS_DIR = Path(C.get(\"results_dir\", \"../results\"))\n",
    "def _latest_run_dir(results_dir: Path) -> Path:\n",
    "    runs = sorted(results_dir.glob(\"*_lstm\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    if not runs: raise FileNotFoundError(\"Kein RUN_DIR gefunden. Bitte Block 3 trainieren.\")\n",
    "    return runs[0]\n",
    "\n",
    "RUN_DIR = _latest_run_dir(RESULTS_DIR)\n",
    "print(\"RUN_DIR:\", RUN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70085932-0e7c-4267-a84a-55b823b98d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Artefakte laden ---\n",
    "MODEL_PATH  = RUN_DIR / \"model.keras\"\n",
    "SCALER_PATH = RUN_DIR / \"scaler.joblib\"\n",
    "CFG_PATH    = RUN_DIR / \"config.json\"\n",
    "assert MODEL_PATH.exists() and SCALER_PATH.exists() and CFG_PATH.exists()\n",
    "\n",
    "with open(CFG_PATH, \"r\") as f:\n",
    "    RCFG = json.load(f)\n",
    "\n",
    "# Konsistenz (Lookback/Horizon) prüfen\n",
    "assert int(RCFG[\"horizon\"]) == HORIZON and int(RCFG[\"lookback\"]) == LOOKBACK\n",
    "\n",
    "model  = keras.models.load_model(MODEL_PATH, compile=False)\n",
    "scaler = joblib.load(SCALER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "823511f8-37a8-45ef-b581-8afa6625874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Daten laden ---\n",
    "eps_tag   = f\"{EPS_MODE}{str(EPSILON).replace('.','p')}\"\n",
    "TRAIN_CSV = f\"../data/{TICKER}_{INTERVAL}_{START}_{END}_cls_h{HORIZON}_{eps_tag}.csv\"\n",
    "df = pd.read_csv(TRAIN_CSV, index_col=0, parse_dates=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0753df2d-817e-405e-ab22-a66be6d3f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Features bestimmen: 1) aus RUN-Config, 2) andernfalls aus YAML v2 ---\n",
    "OHLCV = {\"open\",\"high\",\"low\",\"close\",\"volume\"}\n",
    "if \"features\" in RCFG and RCFG[\"features\"]:\n",
    "    FEATURES = [c for c in RCFG[\"features\"] if c in df.columns]\n",
    "else:\n",
    "    with open(f\"../data/features_{FEATURESET}.yml\",\"r\") as f:\n",
    "        meta = yaml.safe_load(f) or {}\n",
    "    FEATURES = [c for c in meta.get(\"features\", []) if c in df.columns]\n",
    "assert len(FEATURES) > 0, \"Keine Features gefunden.\"\n",
    "\n",
    "X = df[FEATURES].copy()\n",
    "y = df[\"target\"].astype(int).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24824a33-b6a3-4b61-b363-2551d40fda8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chronologische Splits (70/15/15)\n",
    "n = len(df)\n",
    "n_train = int(n*0.70); n_val = int(n*0.15); n_test = n - n_train - n_val\n",
    "train_idx = slice(0, n_train)\n",
    "val_idx   = slice(n_train, n_train + n_val)\n",
    "test_idx  = slice(n_train + n_val, n)\n",
    "\n",
    "X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "X_val,   y_val   = X.iloc[val_idx],   y.iloc[val_idx]\n",
    "X_test,  y_test  = X.iloc[test_idx],  y.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6584d486-4b95-4f2c-a270-0fd2c5fc839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Skalierung ---\n",
    "X_train_s = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=FEATURES)\n",
    "X_val_s   = pd.DataFrame(scaler.transform(X_val),   index=X_val.index,   columns=FEATURES)\n",
    "X_test_s  = pd.DataFrame(scaler.transform(X_test),  index=X_test.index,  columns=FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aebd466-487b-4b3f-b3c5-f3dad3a88c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Windowing ---\n",
    "def make_windows(X_df, y_ser, lookback):\n",
    "    Xv = X_df.values.astype(np.float32); yv = y_ser.values.astype(np.int32)\n",
    "    xs, ys, idx_end = [], [], []\n",
    "    for i in range(lookback-1, len(X_df)):\n",
    "        xs.append(Xv[i - lookback + 1 : i + 1]); ys.append(yv[i]); idx_end.append(X_df.index[i])\n",
    "    return np.stack(xs, 0), np.array(ys), pd.DatetimeIndex(idx_end)\n",
    "\n",
    "Xtr_win, ytr, idx_tr = make_windows(X_train_s, y_train, LOOKBACK)\n",
    "Xva_win, yva, idx_va = make_windows(X_val_s,   y_val,   LOOKBACK)\n",
    "Xte_win, yte, idx_te = make_windows(X_test_s,  y_test,  LOOKBACK)\n",
    "\n",
    "def to_ds(X, y, batch, shuffle):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if shuffle: ds = ds.shuffle(len(X), seed=SEED, reshuffle_each_iteration=False)\n",
    "    return ds.batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_val  = to_ds(Xva_win, yva, BATCH, shuffle=False)\n",
    "ds_test = to_ds(Xte_win, yte, BATCH, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c71bb7ef-7955-4b2f-b901-68f04327ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roh-Wahrscheinlichkeiten\n",
    "y_val_proba  = model.predict(ds_val,  verbose=0).ravel()\n",
    "y_test_proba = model.predict(ds_test, verbose=0).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f1ac0c3-a5b9-4799-bff4-7eff4450611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalibriermethode gewählt: isotonic | Brier raw/iso/platt (VAL): 0.2470/0.2415/0.2483\n"
     ]
    }
   ],
   "source": [
    "# --- Kalibrierungskandidaten ---\n",
    "# 1) Isotonic\n",
    "iso = IsotonicRegression(out_of_bounds=\"clip\").fit(y_val_proba, yva)\n",
    "val_iso = iso.transform(y_val_proba)\n",
    "test_iso = iso.transform(y_test_proba)\n",
    "\n",
    "# 2) Platt scaling (LogisticRegression auf den Scores)\n",
    "platt = LogisticRegression(max_iter=1000)\n",
    "platt.fit(y_val_proba.reshape(-1,1), yva)\n",
    "val_platt  = platt.predict_proba(y_val_proba.reshape(-1,1))[:,1]\n",
    "test_platt = platt.predict_proba(y_test_proba.reshape(-1,1))[:,1]\n",
    "\n",
    "# Val-Brier vergleichen → beste Methode wählen\n",
    "brier_val_raw   = brier_score_loss(yva, y_val_proba)\n",
    "brier_val_iso   = brier_score_loss(yva, val_iso)\n",
    "brier_val_platt = brier_score_loss(yva, val_platt)\n",
    "\n",
    "if brier_val_platt <= brier_val_iso:\n",
    "    CAL_METHOD = \"platt\"\n",
    "    y_val_cal, y_test_cal = val_platt, test_platt\n",
    "    calibrator_obj = platt\n",
    "else:\n",
    "    CAL_METHOD = \"isotonic\"\n",
    "    y_val_cal, y_test_cal = val_iso, test_iso\n",
    "    calibrator_obj = iso\n",
    "\n",
    "joblib.dump(calibrator_obj, RUN_DIR / f\"calibrator_{CAL_METHOD}.joblib\")\n",
    "print(f\"Kalibriermethode gewählt: {CAL_METHOD} | Brier raw/iso/platt (VAL): \"\n",
    "      f\"{brier_val_raw:.4f}/{brier_val_iso:.4f}/{brier_val_platt:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85089a89-a198-472a-aa89-081c61364155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Backward-compat alias so ältere Zellen nicht brechen ---\n",
    "y_val_proba_cal  = y_val_cal\n",
    "y_test_proba_cal = y_test_cal\n",
    "calib_name = CAL_METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "044f863e-5335-4c87-b4ed-079c27b30794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (test):\n",
      " [[ 68 155]\n",
      " [ 64 165]]\n",
      "MCC=0.028 | BalAcc=0.513 | AUROC=0.477 | AUPRC=0.489 | Brier raw→cal 0.2603→0.2899\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "def choose_threshold(y_true, y_prob, strategy=\"max_mcc\", pos_rate_bounds=(0.35,0.65)):\n",
    "    uniq = np.unique(y_prob); cand = np.r_[0.0, uniq, 1.0]\n",
    "    best_t, best_s = 0.5, -1.0\n",
    "    for t in cand:\n",
    "        yp = (y_prob >= t).astype(int)\n",
    "        pr = float(yp.mean())\n",
    "        if not (pos_rate_bounds[0] <= pr <= pos_rate_bounds[1]): \n",
    "            continue\n",
    "        s = matthews_corrcoef(y_true, yp)\n",
    "        if s > best_s: best_s, best_t = float(s), float(t)\n",
    "    if best_s < 0:  # Fallback\n",
    "        return 0.5, 0.0\n",
    "    return best_t, best_s\n",
    "\n",
    "thr, score_val = choose_threshold(yva, y_val_cal, pos_rate_bounds=(0.35,0.65))\n",
    "y_test_pred = (y_test_cal >= thr).astype(int)\n",
    "\n",
    "# Metriken\n",
    "cm   = confusion_matrix(yte, y_test_pred)\n",
    "rep  = classification_report(yte, y_test_pred, digits=3, output_dict=True)\n",
    "fpr, tpr, _ = roc_curve(yte, y_test_cal); roc_auc = auc(fpr, tpr)\n",
    "prec, rec, _ = precision_recall_curve(yte, y_test_cal); ap = average_precision_score(yte, y_test_cal)\n",
    "brier_raw = brier_score_loss(yte, y_test_proba); brier_cal = brier_score_loss(yte, y_test_cal)\n",
    "bal_acc = balanced_accuracy_score(yte, y_test_pred)\n",
    "mcc     = matthews_corrcoef(yte, y_test_pred)\n",
    "\n",
    "print(\"Confusion matrix (test):\\n\", cm)\n",
    "print(f\"MCC={mcc:.3f} | BalAcc={bal_acc:.3f} | AUROC={roc_auc:.3f} | AUPRC={ap:.3f} | Brier raw→cal {brier_raw:.4f}→{brier_cal:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df77d65d-26fe-4609-898c-800dee5c857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (test):\n",
      " [[ 68 155]\n",
      " [ 64 165]]\n",
      "MCC: 0.028 BalancedAcc: 0.513 AUROC: 0.477 AUPRC: 0.489\n"
     ]
    }
   ],
   "source": [
    "# --- Test-Evaluation (kalibriert @ thr) ---\n",
    "y_test_pred = (y_test_proba_cal >= thr).astype(int)\n",
    "\n",
    "cm   = confusion_matrix(yte, y_test_pred)\n",
    "rep  = classification_report(yte, y_test_pred, digits=3, output_dict=True)\n",
    "fpr, tpr, _ = roc_curve(yte, y_test_proba_cal)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "prec, rec, _ = precision_recall_curve(yte, y_test_proba_cal)\n",
    "ap = average_precision_score(yte, y_test_proba_cal)\n",
    "brier_raw = brier_score_loss(yte, y_test_proba)       # vor Kal.\n",
    "brier_cal = brier_score_loss(yte, y_test_proba_cal)   # nach Kal.\n",
    "bal_acc = balanced_accuracy_score(yte, y_test_pred)\n",
    "mcc     = matthews_corrcoef(yte, y_test_pred)\n",
    "\n",
    "print(\"Confusion matrix (test):\\n\", cm)\n",
    "print(\"MCC:\", round(mcc,3), \"BalancedAcc:\", round(bal_acc,3), \"AUROC:\", round(roc_auc,3), \"AUPRC:\", round(ap,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1404cda-f83e-43b6-8e8b-e31d868a1ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC Bootstrap CI [2.5,50,97.5]: [np.float64(-0.075), np.float64(0.011), np.float64(0.115)]\n"
     ]
    }
   ],
   "source": [
    "# --- Bootstrap-CI fürs MCC (Blocksampling) ---\n",
    "rng = np.random.default_rng(SEED)\n",
    "def block_bootstrap_mcc(y_true, y_prob, threshold, n=300, block=LOOKBACK):\n",
    "    idx = np.arange(len(y_true))\n",
    "    scores = []\n",
    "    for _ in range(n):\n",
    "        starts = rng.integers(0, max(1, len(idx)-block+1), size=max(1, len(idx)//block))\n",
    "        bs = np.concatenate([np.arange(s, min(s+block, len(idx))) for s in starts])\n",
    "        yp = (y_prob[bs] >= threshold).astype(int)\n",
    "        scores.append(matthews_corrcoef(y_true[bs], yp))\n",
    "    return np.percentile(scores, [2.5, 50, 97.5]).astype(float)\n",
    "mcc_ci = block_bootstrap_mcc(yte, y_test_proba_cal, thr, n=300, block=LOOKBACK)\n",
    "print(\"MCC Bootstrap CI [2.5,50,97.5]:\", [round(x,3) for x in mcc_ci])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "262a19eb-6fcf-415c-80ae-3eb318ce44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plots ---\n",
    "FIG_DIR = RUN_DIR / \"figures\"; FIG_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ROC / PR\n",
    "plt.figure(figsize=(6,4)); plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
    "plt.plot([0,1],[0,1],\"--\"); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC (Test)\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(FIG_DIR / \"roc_test.png\", dpi=160); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,4)); plt.plot(rec, prec, label=f\"AP={ap:.3f}\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall (Test)\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(FIG_DIR / \"pr_test.png\", dpi=160); plt.close()\n",
    "\n",
    "# Kalibrierungskurve\n",
    "prob_true, prob_pred = calibration_curve(yte, y_test_cal, n_bins=10, strategy=\"quantile\")\n",
    "plt.figure(figsize=(6,4)); plt.plot([0,1],[0,1],\"--\"); plt.plot(prob_pred, prob_true, marker=\"o\")\n",
    "plt.xlabel(\"Vorhergesagt\"); plt.ylabel(\"Tatsächlich\"); plt.title(f\"Kalibrierung (Test) – {CAL_METHOD}\")\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / \"calibration_test.png\", dpi=160); plt.close()\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(4.8,4.2))\n",
    "plt.imshow(cm, interpolation=\"nearest\"); plt.title(\"Confusion Matrix (Test)\"); plt.colorbar()\n",
    "ticks = np.arange(2); plt.xticks(ticks, [\"0\",\"1\"]); plt.yticks(ticks, [\"0\",\"1\"])\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / \"cm_test.png\", dpi=160); plt.close()\n",
    "\n",
    "# Histogramm Probas\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(y_test_proba, bins=30, alpha=0.6, label=\"raw\")\n",
    "plt.hist(y_test_cal,   bins=30, alpha=0.6, label=f\"calibrated ({CAL_METHOD})\")\n",
    "plt.axvline(thr, linestyle=\"--\", label=f\"thr={thr:.3f}\")\n",
    "plt.title(\"P(y=1) – raw vs. calibrated (Test)\")\n",
    "plt.legend(); plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"proba_hist_raw_vs_cal.png\", dpi=160); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08cfd2af-70a6-4187-ab6f-c0ffb4d3c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions-CSV\n",
    "preds_test = pd.DataFrame({\n",
    "    \"timestamp\": idx_te, \"y_true\": yte,\n",
    "    \"y_proba_raw\": y_test_proba, \"y_proba_cal\": y_test_cal, \"y_pred\": y_test_pred,\n",
    "}).set_index(\"timestamp\")\n",
    "preds_test.to_csv(RUN_DIR / \"preds_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac31e9e3-bb48-4f08-b07b-01adcb99f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Backtest wie gehabt (Entry@t und @t+1) ---\n",
    "close = df[\"close\"].copy()\n",
    "fwd_logret = (np.log(close.shift(-HORIZON)) - np.log(close)).reindex(idx_te)\n",
    "signals_t  = (preds_test[\"y_proba_cal\"] >= thr).astype(int).reindex(idx_te)\n",
    "signals_t1 = signals_t.shift(1).fillna(0)\n",
    "\n",
    "strategy_logret_t  = (signals_t  * fwd_logret).fillna(0)\n",
    "strategy_logret_t1 = (signals_t1 * fwd_logret).fillna(0)\n",
    "equity_t  = strategy_logret_t.cumsum().apply(np.exp)\n",
    "equity_t1 = strategy_logret_t1.cumsum().apply(np.exp)\n",
    "\n",
    "bh_logret = (np.log(close.reindex(idx_te)) - np.log(close.reindex(idx_te).iloc[0])).fillna(0)\n",
    "bh_equity = np.exp(bh_logret)\n",
    "\n",
    "def _sharpe(logrets, periods_per_year=252):\n",
    "    mu = logrets.mean() * periods_per_year\n",
    "    sigma = logrets.std(ddof=1) * np.sqrt(periods_per_year)\n",
    "    return float(mu / (sigma + 1e-12))\n",
    "\n",
    "def _cagr(eq, periods_per_year=252):\n",
    "    T = len(eq) / periods_per_year\n",
    "    return float((eq.iloc[-1] / eq.iloc[0])**(1.0/T) - 1.0)\n",
    "\n",
    "backtest = {\n",
    "    \"n_trades\": int(signals_t.sum()),\n",
    "    \"avg_holding_h\": HORIZON,\n",
    "    \"strategy_t\": {\"CAGR\": _cagr(equity_t),  \"Sharpe\": _sharpe(strategy_logret_t.dropna()),  \"final_equity\": float(equity_t.iloc[-1])},\n",
    "    \"strategy_t1\":{\"CAGR\": _cagr(equity_t1), \"Sharpe\": _sharpe(strategy_logret_t1.dropna()), \"final_equity\": float(equity_t1.iloc[-1])},\n",
    "    \"buy_hold\":  {\"CAGR\": _cagr(bh_equity),  \"final_equity\": float(bh_equity.iloc[-1])},\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(equity_t.index, equity_t.values,   label=\"Entry@t (optimistisch)\")\n",
    "plt.plot(equity_t1.index, equity_t1.values, label=\"Entry@t+1 (konservativ)\")\n",
    "plt.plot(bh_equity.index, bh_equity.values, label=\"Buy & Hold\", linestyle=\"--\")\n",
    "plt.title(f\"Equity Curves (H={HORIZON})\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(FIG_DIR / \"equity_curves_t_vs_t1.png\", dpi=160); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0a1c3dd-3650-4c1e-845e-63c98a6421e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier raw=0.2603 → calibrated=0.2899\n"
     ]
    }
   ],
   "source": [
    "# --- Vor/Nach: Histogramm + Brier ---\n",
    "calib_name = \"isotonic\"  # oder aus deiner Pipeline lesen\n",
    "\n",
    "brier_raw = brier_score_loss(yte, y_test_proba)\n",
    "brier_cal = brier_score_loss(yte, y_test_proba_cal)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(y_test_proba,      bins=30, alpha=0.6, label=\"raw\")\n",
    "plt.hist(y_test_proba_cal,  bins=30, alpha=0.6, label=f\"calibrated ({calib_name})\")\n",
    "plt.axvline(thr, linestyle=\"--\", label=f\"thr={thr:.3f}\")\n",
    "plt.title(\"P(y=1) – raw vs. calibrated (Test)\")\n",
    "plt.legend(); plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"proba_hist_raw_vs_cal.png\", dpi=160); plt.close()\n",
    "\n",
    "print(f\"Brier raw={brier_raw:.4f} → calibrated={brier_cal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "200036f8-d7ff-41fe-aa6f-ae6903888710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Block 4 abgeschlossen. Artefakte:\n",
      " - ..\\results\\2025-10-18_16-01-40_lstm\\preds_test.csv\n",
      " - ..\\results\\2025-10-18_16-01-40_lstm\\evaluation.json\n",
      " - ..\\results\\2025-10-18_16-01-40_lstm\\figures\n"
     ]
    }
   ],
   "source": [
    "out = {\n",
    "    \"config\": RCFG,\n",
    "    \"features_used\": FEATURES,\n",
    "    \"calibration\": {\n",
    "        \"chosen\": CAL_METHOD,\n",
    "        \"paths\": {CAL_METHOD: str(RUN_DIR / f\"calibrator_{CAL_METHOD}.joblib\")},\n",
    "        \"val_brier\": {\"raw\": float(brier_val_raw), \"iso\": float(brier_val_iso), \"platt\": float(brier_val_platt)},\n",
    "        \"test_brier\": {\"raw\": float(brier_raw), \"cal\": float(brier_cal)}\n",
    "    },\n",
    "    \"threshold_selection\": {\n",
    "        \"strategy\": \"max_mcc_with_pos_rate_bounds\",\n",
    "        \"threshold\": float(thr),\n",
    "        \"pos_rate_bounds\": [0.35, 0.65],\n",
    "        \"val_mcc\": float(score_val),\n",
    "        \"test_pred_pos_rate\": float((y_test_cal >= thr).mean())\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        \"test\": {\n",
    "            \"roc_auc\": float(roc_auc), \"auprc\": float(ap), \"brier\": float(brier_cal),\n",
    "            \"balanced_accuracy\": float(bal_acc), \"mcc\": float(mcc),\n",
    "            \"confusion_matrix\": cm.tolist(), \"report\": rep\n",
    "        }\n",
    "    },\n",
    "    \"backtest\": backtest,\n",
    "}\n",
    "with open(RUN_DIR / \"evaluation.json\", \"w\") as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "\n",
    "print(\"\\nBlock 4 abgeschlossen. Artefakte:\")\n",
    "print(\" -\", RUN_DIR / \"preds_test.csv\")\n",
    "print(\" -\", RUN_DIR / \"evaluation.json\")\n",
    "print(\" -\", RUN_DIR / \"figures\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c23181-39d6-4d12-b294-a152d62e251b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3852acd-f9d3-495d-b3ff-321f8a6f36c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (finance-lstm)",
   "language": "python",
   "name": "finance-lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
