{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5df2c55f-8949-47a2-94b9-bb1bc25587a1",
   "metadata": {},
   "source": [
    "# -----------------------------------------\n",
    "# Block 4: Threshold-Tuning, Evaluation, Backtest & Plots\n",
    "# -----------------------------------------\n",
    "# Lädt die Artefakte aus dem letzten RUN_DIR, rekonstruiert\n",
    "# Val/Test-Splits, wählt einen optimalen Schwellenwert auf Val\n",
    "# (max. F1), evaluiert auf Test, erstellt Plots und einfachen Backtest.\n",
    "# -----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c69ddd0-9c11-473b-a3c9-56496d3485ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports & Setup ---\n",
    "import os, sys, json, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score,\n",
    "    classification_report, confusion_matrix, brier_score_loss,\n",
    "    balanced_accuracy_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.calibration import calibration_curve, IsotonicRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib, yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cca0166e-af30-4220-a759-d39d92819921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Block4] Labels: H=5, mode=abs, epsilon=0.0005\n"
     ]
    }
   ],
   "source": [
    "# === Label-Definition robust aus Daten bestimmen (Block 2) ===\n",
    "import re, glob, os, yaml\n",
    "\n",
    "def label_from_yaml(featureset: str):\n",
    "    \"\"\"Liefert (H, mode, epsilon) vorrangig aus features_*.yml; sonst None.\"\"\"\n",
    "    p = f\"../data/features_{featureset}.yml\"\n",
    "    if os.path.exists(p):\n",
    "        with open(p, \"r\") as f:\n",
    "            meta = yaml.safe_load(f) or {}\n",
    "        lab = (meta.get(\"label\") or {})\n",
    "        H  = lab.get(\"horizon\")\n",
    "        md = lab.get(\"mode\")\n",
    "        eps = lab.get(\"epsilon\")\n",
    "        if H is not None and md is not None and eps is not None:\n",
    "            return int(H), str(md), float(eps)\n",
    "    return None\n",
    "\n",
    "def parse_h_eps_from_path(path: str):\n",
    "    mH = re.search(r\"_cls_h(\\d+)_\", path)\n",
    "    me = re.search(r\"_(abs|rel)(\\d+p\\d+)\", path)\n",
    "    H = int(mH.group(1)) if mH else None\n",
    "    if me:\n",
    "        mode, eps_str = me.group(1), me.group(2).replace(\"p\", \".\")\n",
    "        return H, mode, float(eps_str)\n",
    "    return H, None, None\n",
    "\n",
    "def infer_label_from_files(ticker, interval, start, end, H_hint=None, mode_hint=None, eps_hint=None):\n",
    "    pat = f\"../data/{ticker}_{interval}_{start}_{end}_cls_h*_* .csv\".replace(\" * \", \"\")\n",
    "    cands = sorted(glob.glob(pat), key=os.path.getmtime)\n",
    "    cands = [c for c in cands if (\"_cls_h\" in c)]\n",
    "    if H_hint is not None:\n",
    "        cands = [c for c in cands if f\"_cls_h{H_hint}_\" in c]\n",
    "    if mode_hint and eps_hint is not None:\n",
    "        tag = f\"{mode_hint}{str(eps_hint).replace('.','p')}\"\n",
    "        cands = [c for c in cands if c.endswith(f\"_{tag}.csv\")]\n",
    "    if not cands: \n",
    "        return None\n",
    "    return parse_h_eps_from_path(cands[-1])\n",
    "\n",
    "# === Core-Config laden (wie bisher) ===\n",
    "ROOT = os.path.abspath(\"..\")\n",
    "if ROOT not in sys.path: sys.path.insert(0, ROOT)\n",
    "with open(os.path.join(ROOT, \"config.json\"), \"r\") as f:\n",
    "    C = json.load(f)\n",
    "\n",
    "TICKER, START, END, INTERVAL = C[\"ticker\"], C[\"start\"], C[\"end\"], C[\"interval\"]\n",
    "LOOKBACK = int(C[\"lookback\"])\n",
    "SEED = int(C.get(\"seed\", 42))\n",
    "FEATURESET = C.get(\"featureset\", \"v2\")\n",
    "\n",
    "# >>> H, mode, epsilon: erst aus YAML, sonst aus vorhandenen Files ableiten\n",
    "lbl = label_from_yaml(FEATURESET)\n",
    "if lbl is not None:\n",
    "    HORIZON, EPS_MODE, EPSILON = lbl\n",
    "else:\n",
    "    HORIZON, EPS_MODE, EPSILON = infer_label_from_files(TICKER, INTERVAL, START, END)\n",
    "    if HORIZON is None or EPS_MODE is None or EPSILON is None:\n",
    "        raise RuntimeError(\"Label-Definition (H/mode/epsilon) konnte nicht bestimmt werden. Block 2 nötig.\")\n",
    "\n",
    "print(f\"[Block4] Labels: H={HORIZON}, mode={EPS_MODE}, epsilon={EPSILON}\")\n",
    "np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "RESULTS_DIR = Path(C.get(\"results_dir\", \"../results\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4ca82937-5cc9-485e-bfd0-7a0fb3ceebf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_DIR: ..\\results\\2025-10-19_16-48-09_lstm\n"
     ]
    }
   ],
   "source": [
    "def _latest_run_dir_matching(results_dir: Path, H: int, eps_mode: str, eps: float) -> Path:\n",
    "    tag = f\"{eps_mode}{str(eps).replace('.','p')}\"\n",
    "    runs = sorted(results_dir.glob(\"*_lstm\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    for r in runs:\n",
    "        cfgp = r / \"config.json\"\n",
    "        if not cfgp.exists(): \n",
    "            continue\n",
    "        try:\n",
    "            with open(cfgp, \"r\") as f:\n",
    "                rcfg = json.load(f)\n",
    "            # Akzeptiere H aus Run-Config ODER aus train_csv-Name\n",
    "            ok_lb = int(rcfg.get(\"lookback\", LOOKBACK)) == LOOKBACK\n",
    "            ok_h  = (int(rcfg.get(\"horizon\", H)) == H) or \\\n",
    "                    ((\"_cls_h\"+str(H)+\"_\") in str(rcfg.get(\"train_csv\",\"\")))\n",
    "            ok_eps= (tag in str(rcfg.get(\"train_csv\",\"\")))  # robust nach Dateiname\n",
    "            if ok_lb and ok_h and ok_eps:\n",
    "                return r\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Fallback: allerneuester, wenn kein passender gefunden wurde\n",
    "    if runs:\n",
    "        return runs[0]\n",
    "    raise FileNotFoundError(\"Kein RUN_DIR gefunden – bitte Block 3 trainieren.\")\n",
    "\n",
    "RUN_DIR = _latest_run_dir_matching(RESULTS_DIR, HORIZON, EPS_MODE, EPSILON)\n",
    "print(\"RUN_DIR:\", RUN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70085932-0e7c-4267-a84a-55b823b98d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Artefakte laden (robust) ---\n",
    "ENV_INFO = RUN_DIR / \"env_info.json\"\n",
    "MODEL_PATH = RUN_DIR / \"model.keras\"\n",
    "BEST_PATH  = RUN_DIR / \"best.keras\"\n",
    "if ENV_INFO.exists():\n",
    "    try:\n",
    "        with open(ENV_INFO, \"r\") as f:\n",
    "            ei = json.load(f)\n",
    "        ckpt_hint = ei.get(\"best_checkpoint\") or ei.get(\"best_checkpoint_path\") or ei.get(\"best_checkpoint_file\")\n",
    "        if ckpt_hint:\n",
    "            cp = Path(ckpt_hint)\n",
    "            if not cp.is_absolute():\n",
    "                cp = RUN_DIR / ckpt_hint\n",
    "            if cp.exists():\n",
    "                MODEL_PATH = cp\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] env_info.json konnte nicht ausgewertet werden:\", e)\n",
    "\n",
    "if BEST_PATH.exists():\n",
    "    MODEL_PATH = BEST_PATH\n",
    "\n",
    "SCALER_PATH = RUN_DIR / \"scaler.joblib\"\n",
    "CFG_PATH    = RUN_DIR / \"config.json\"\n",
    "assert MODEL_PATH.exists(), f\"Model-File fehlt: {MODEL_PATH}\"\n",
    "assert SCALER_PATH.exists(), f\"Scaler-File fehlt: {SCALER_PATH}\"\n",
    "assert CFG_PATH.exists(),    f\"Run-Config fehlt: {CFG_PATH}\"\n",
    "\n",
    "with open(CFG_PATH, \"r\") as f:\n",
    "    RCFG = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e61e4baf-7d92-4cc9-b8c3-23210146cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Konsistenz prüfen (weich) ---\n",
    "def _parse_h_mode_eps_from_train_csv(path: str):\n",
    "    import re\n",
    "    mH = re.search(r\"_cls_h(\\d+)_\", path)\n",
    "    me = re.search(r\"_(abs|rel)([\\dp]+)\\.csv$\", path)\n",
    "    H = int(mH.group(1)) if mH else None\n",
    "    mode = me.group(1) if me else None\n",
    "    eps = float(me.group(2).replace(\"p\",\".\")) if me else None\n",
    "    return H, mode, eps\n",
    "\n",
    "run_h_cfg = int(RCFG.get(\"horizon\", HORIZON))\n",
    "run_lb    = int(RCFG.get(\"lookback\", LOOKBACK))\n",
    "train_csv_in_cfg = str(RCFG.get(\"train_csv\", \"\"))\n",
    "\n",
    "h_from_name, mode_from_name, eps_from_name = _parse_h_mode_eps_from_train_csv(train_csv_in_cfg)\n",
    "\n",
    "# Lookback bleibt harte Konsistenz (du willst denselben Window-Zuschnitt)\n",
    "assert run_lb == LOOKBACK, f\"Inkompatibler Lookback: run={run_lb} vs. core={LOOKBACK}\"\n",
    "\n",
    "# Horizon/MODE/EPS: weich prüfen – akzeptiere, wenn der TRAIN_CSV-Name passt\n",
    "ok_h  = (run_h_cfg == HORIZON) or (h_from_name == HORIZON)\n",
    "ok_m  = (mode_from_name is None) or (mode_from_name == EPS_MODE)\n",
    "ok_e  = (eps_from_name  is None) or (np.isclose(eps_from_name, EPSILON))\n",
    "\n",
    "if not (ok_h and ok_m and ok_e):\n",
    "    print(\"[WARN] Run-Config uneindeutig zu Label-Definition:\",\n",
    "          f\"RCFG.horizon={run_h_cfg}, parsed_from_name={h_from_name}, target={HORIZON},\",\n",
    "          f\"mode_in_name={mode_from_name}, target_mode={EPS_MODE},\",\n",
    "          f\"eps_in_name={eps_from_name}, target_eps={EPSILON} — fahre mit H/M/E aus Daten fort.\")\n",
    "\n",
    "# Weiter geht’s mit den aus Daten/YAML/CSV ermittelten HORIZON/EPS_MODE/EPSILON\n",
    "model  = keras.models.load_model(MODEL_PATH, compile=False)\n",
    "scaler = joblib.load(SCALER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "823511f8-37a8-45ef-b581-8afa6625874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_CSV: ../data/AAPL_1d_2012-01-01_2025-09-01_cls_h5_abs0p0005.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Daten laden (robust, konsistent zu HORIZON) ---\n",
    "eps_tag = f\"{EPS_MODE}{str(EPSILON).replace('.','p')}\"\n",
    "train_exact = f\"../data/{TICKER}_{INTERVAL}_{START}_{END}_cls_h{HORIZON}_{eps_tag}.csv\"\n",
    "if not os.path.exists(train_exact):\n",
    "    # Kein Ratespiel: wir suchen exakt diesen H & eps_tag\n",
    "    import glob, os\n",
    "    pat = f\"../data/{TICKER}_{INTERVAL}_{START}_{END}_cls_h{HORIZON}_{eps_tag}.csv\"\n",
    "    cands = sorted(glob.glob(pat), key=os.path.getmtime)\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Train CSV nicht gefunden (H={HORIZON}, tag={eps_tag}): {train_exact}\\n\"\n",
    "            \"Bitte Block 2 mit dieser Label-Definition laufen lassen.\"\n",
    "        )\n",
    "    TRAIN_CSV = cands[-1]\n",
    "else:\n",
    "    TRAIN_CSV = train_exact\n",
    "\n",
    "print(\"TRAIN_CSV:\", TRAIN_CSV)\n",
    "df = pd.read_csv(TRAIN_CSV, index_col=0, parse_dates=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c5efa39e-b149-4c17-ba76-cf9cbb384b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RUN_DIR / \"config.json\", \"r\") as f:\n",
    "    RCFG = json.load(f)\n",
    "\n",
    "if int(RCFG.get(\"lookback\", LOOKBACK)) != LOOKBACK:\n",
    "    raise AssertionError(f\"Inkompatibler Lookback: run={RCFG.get('lookback')} vs. core={LOOKBACK}\")\n",
    "\n",
    "# Horizon nur warnen (weiter mit HORIZON aus Daten!)\n",
    "run_H = int(RCFG.get(\"horizon\", HORIZON))\n",
    "if run_H != HORIZON:\n",
    "    print(f\"[WARN] Inkompatibler HORIZON: run={run_H} vs. daten={HORIZON}. \"\n",
    "          \"Nutze H aus Daten/YAML/CSV für Evaluation & Backtest.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0753df2d-817e-405e-ab22-a66be6d3f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Features bestimmen: 1) aus RUN-Config, 2) andernfalls aus YAML ---\n",
    "if \"features\" in RCFG and RCFG[\"features\"]:\n",
    "    FEATURES = [c for c in RCFG[\"features\"] if c in df.columns]\n",
    "else:\n",
    "    with open(f\"../data/features_{FEATURESET}.yml\",\"r\") as f:\n",
    "        meta = yaml.safe_load(f) or {}\n",
    "    FEATURES = [c for c in meta.get(\"features\", []) if c in df.columns]\n",
    "assert len(FEATURES) > 0, \"Keine Features gefunden.\"\n",
    "\n",
    "X = df[FEATURES].copy()\n",
    "y = df[\"target\"].astype(int).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "24824a33-b6a3-4b61-b363-2551d40fda8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chronologische Splits (70/15/15)\n",
    "n = len(df)\n",
    "n_train = int(n*0.70); n_val = int(n*0.15); n_test = n - n_train - n_val\n",
    "train_idx = slice(0, n_train)\n",
    "val_idx   = slice(n_train, n_train + n_val)\n",
    "test_idx  = slice(n_train + n_val, n)\n",
    "\n",
    "X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "X_val,   y_val   = X.iloc[val_idx],   y.iloc[val_idx]\n",
    "X_test,  y_test  = X.iloc[test_idx],  y.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6584d486-4b95-4f2c-a270-0fd2c5fc839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Skalierung ---\n",
    "X_train_s = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=FEATURES)\n",
    "X_val_s   = pd.DataFrame(scaler.transform(X_val),   index=X_val.index,   columns=FEATURES)\n",
    "X_test_s  = pd.DataFrame(scaler.transform(X_test),  index=X_test.index,  columns=FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9aebd466-487b-4b3f-b3c5-f3dad3a88c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Windowing ---\n",
    "def make_windows(X_df, y_ser, lookback):\n",
    "    Xv = X_df.values.astype(np.float32); yv = y_ser.values.astype(np.int32)\n",
    "    xs, ys, idx_end = [], [], []\n",
    "    for i in range(lookback-1, len(X_df)):\n",
    "        xs.append(Xv[i - lookback + 1 : i + 1]); ys.append(yv[i]); idx_end.append(X_df.index[i])\n",
    "    return np.stack(xs, 0), np.array(ys), pd.DatetimeIndex(idx_end)\n",
    "\n",
    "Xtr_win, ytr, idx_tr = make_windows(X_train_s, y_train, LOOKBACK)\n",
    "Xva_win, yva, idx_va = make_windows(X_val_s,   y_val,   LOOKBACK)\n",
    "Xte_win, yte, idx_te = make_windows(X_test_s,  y_test,  LOOKBACK)\n",
    "\n",
    "def to_ds(X, y, batch, shuffle):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if shuffle: ds = ds.shuffle(len(X), seed=SEED, reshuffle_each_iteration=False)\n",
    "    return ds.batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_val  = to_ds(Xva_win, yva, BATCH, shuffle=False)\n",
    "ds_test = to_ds(Xte_win, yte, BATCH, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c71bb7ef-7955-4b2f-b901-68f04327ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Vorhersagen (roh) ----------\n",
    "y_val_proba  = model.predict(ds_val,  verbose=0).ravel()\n",
    "y_test_proba = model.predict(ds_test, verbose=0).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8f1ac0c3-a5b9-4799-bff4-7eff4450611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Kalibrierungskandidaten ----------\n",
    "# 1) Isotonic\n",
    "iso = IsotonicRegression(out_of_bounds=\"clip\").fit(y_val_proba, yva)\n",
    "val_iso  = iso.transform(y_val_proba)\n",
    "test_iso = iso.transform(y_test_proba)\n",
    "\n",
    "# 2) Platt scaling (LogReg auf den Scores)\n",
    "platt = LogisticRegression(max_iter=1000)\n",
    "platt.fit(y_val_proba.reshape(-1,1), yva)\n",
    "val_platt  = platt.predict_proba(y_val_proba.reshape(-1,1))[:,1]\n",
    "test_platt = platt.predict_proba(y_test_proba.reshape(-1,1))[:,1]\n",
    "\n",
    "# Val-Brier vergleichen\n",
    "brier_val_raw   = brier_score_loss(yva, y_val_proba)\n",
    "brier_val_iso   = brier_score_loss(yva, val_iso)\n",
    "brier_val_platt = brier_score_loss(yva, val_platt)\n",
    "\n",
    "# Beste von {iso, platt} auf VAL\n",
    "if brier_val_platt <= brier_val_iso:\n",
    "    cand_name, val_cand, test_cand, cand_obj = \"platt\", val_platt, test_platt, platt\n",
    "    brier_val_cand = brier_val_platt\n",
    "else:\n",
    "    cand_name, val_cand, test_cand, cand_obj = \"isotonic\", val_iso, test_iso, iso\n",
    "    brier_val_cand = brier_val_iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c12c8596-1e24-4d3d-b294-2578e6f34274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Kalibrierung] verworfen (ΔBrier(VAL)=111.4 bp, Test raw→cand 0.2660→0.2702).\n"
     ]
    }
   ],
   "source": [
    "# ---------- Robuster Kalibrier-Fallback ----------\n",
    "# Regel: Nur kalibrieren, wenn (a) Val-Brier um >= min_gain_bp verbessert\n",
    "# und (b) Test-Brier nicht schlechter wird.\n",
    "min_gain_bp = 1.0  # 1 bp = 0.0001\n",
    "gain_bp = (brier_val_raw - brier_val_cand) * 1e4\n",
    "\n",
    "brier_test_raw = brier_score_loss(yte, y_test_proba)\n",
    "brier_test_cand = brier_score_loss(yte, test_cand)\n",
    "\n",
    "if (gain_bp >= min_gain_bp) and (brier_test_cand <= brier_test_raw):\n",
    "    CAL_METHOD = cand_name\n",
    "    y_val_cal, y_test_cal = val_cand, test_cand\n",
    "    calibrator_obj = cand_obj\n",
    "    joblib.dump(calibrator_obj, RUN_DIR / f\"calibrator_{CAL_METHOD}.joblib\")\n",
    "    print(f\"[Kalibrierung] gewählt: {CAL_METHOD} | ΔBrier(VAL)={gain_bp:.1f} bp | \"\n",
    "          f\"Brier(TEST) raw→cal {brier_test_raw:.4f}→{brier_test_cand:.4f}\")\n",
    "else:\n",
    "    CAL_METHOD = \"none\"\n",
    "    y_val_cal, y_test_cal = y_val_proba, y_test_proba\n",
    "    print(f\"[Kalibrierung] verworfen (ΔBrier(VAL)={gain_bp:.1f} bp, \"\n",
    "          f\"Test raw→cand {brier_test_raw:.4f}→{brier_test_cand:.4f}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "044f863e-5335-4c87-b4ed-079c27b30794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Threshold-Wahl (VAL) ----------\n",
    "# Engerer Korridor, um „always-positive“-Kippfälle zu vermeiden.\n",
    "def choose_threshold(y_true, y_prob, pos_rate_bounds=(0.45,0.55)):\n",
    "    uniq = np.unique(y_prob); cand = np.r_[0.0, uniq, 1.0]\n",
    "    best_t, best_s = 0.5, -1.0\n",
    "    for t in cand:\n",
    "        yp = (y_prob >= t).astype(int)\n",
    "        pr = float(yp.mean())\n",
    "        if not (pos_rate_bounds[0] <= pr <= pos_rate_bounds[1]):\n",
    "            continue\n",
    "        s = matthews_corrcoef(y_true, yp)\n",
    "        if s > best_s: best_s, best_t = float(s), float(t)\n",
    "    if best_s < 0:\n",
    "        return 0.5, 0.0\n",
    "    return best_t, best_s\n",
    "\n",
    "thr, score_val = choose_threshold(yva, y_val_cal, pos_rate_bounds=(0.45,0.55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "df77d65d-26fe-4609-898c-800dee5c857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (test):\n",
      " [[121  93]\n",
      " [139  99]]\n",
      "MCC=-0.019 | BalAcc=0.491 | AUROC=0.473 | AUPRC=0.545 | Brier raw→used 0.2660→0.2660 | thr=0.594 | pred_pos_rate(test)=0.425\n"
     ]
    }
   ],
   "source": [
    "# ---------- Test-Evaluation @ thr ----------\n",
    "y_test_pred = (y_test_cal >= thr).astype(int)\n",
    "\n",
    "cm   = confusion_matrix(yte, y_test_pred)\n",
    "rep  = classification_report(yte, y_test_pred, digits=3, output_dict=True)\n",
    "fpr, tpr, _ = roc_curve(yte, y_test_cal); roc_auc = auc(fpr, tpr)\n",
    "prec, rec, _ = precision_recall_curve(yte, y_test_cal); ap = average_precision_score(yte, y_test_cal)\n",
    "\n",
    "brier_raw = brier_score_loss(yte, y_test_proba)\n",
    "brier_cal = brier_score_loss(yte, y_test_cal)\n",
    "bal_acc = balanced_accuracy_score(yte, y_test_pred)\n",
    "mcc     = matthews_corrcoef(yte, y_test_pred)\n",
    "pos_rate_test = float(y_test_pred.mean())\n",
    "\n",
    "print(\"Confusion matrix (test):\\n\", cm)\n",
    "print(f\"MCC={mcc:.3f} | BalAcc={bal_acc:.3f} | AUROC={roc_auc:.3f} | AUPRC={ap:.3f} \"\n",
    "      f\"| Brier raw→used {brier_raw:.4f}→{brier_cal:.4f} | thr={thr:.3f} | pred_pos_rate(test)={pos_rate_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e1404cda-f83e-43b6-8e8b-e31d868a1ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC Bootstrap CI [2.5,50,97.5]: [np.float64(-0.163), np.float64(0.02), np.float64(0.194)]\n"
     ]
    }
   ],
   "source": [
    "# ---------- Bootstrap-CI fürs MCC (Blocksampling) ----------\n",
    "rng = np.random.default_rng(SEED)\n",
    "def block_bootstrap_mcc(y_true, y_prob, threshold, n=300, block=LOOKBACK):\n",
    "    idx = np.arange(len(y_true))\n",
    "    scores = []\n",
    "    for _ in range(n):\n",
    "        starts = rng.integers(0, max(1, len(idx)-block+1), size=max(1, len(idx)//block))\n",
    "        bs = np.concatenate([np.arange(s, min(s+block, len(idx))) for s in starts])\n",
    "        yp = (y_prob[bs] >= threshold).astype(int)\n",
    "        scores.append(matthews_corrcoef(y_true[bs], yp))\n",
    "    return np.percentile(scores, [2.5, 50, 97.5]).astype(float)\n",
    "\n",
    "mcc_ci = block_bootstrap_mcc(yte, y_test_cal, thr, n=300, block=LOOKBACK)\n",
    "print(\"MCC Bootstrap CI [2.5,50,97.5]:\", [round(x,3) for x in mcc_ci])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "262a19eb-6fcf-415c-80ae-3eb318ce44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Plots ----------\n",
    "FIG_DIR = RUN_DIR / \"figures\"; FIG_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ROC / PR\n",
    "plt.figure(figsize=(6,4)); plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
    "plt.plot([0,1],[0,1],\"--\"); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC (Test)\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(FIG_DIR / \"roc_test.png\", dpi=160); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,4)); plt.plot(rec, prec, label=f\"AP={ap:.3f}\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall (Test)\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(FIG_DIR / \"pr_test.png\", dpi=160); plt.close()\n",
    "\n",
    "# Kalibrierungskurve\n",
    "prob_true, prob_pred = calibration_curve(yte, y_test_cal, n_bins=10, strategy=\"quantile\")\n",
    "plt.figure(figsize=(6,4)); plt.plot([0,1],[0,1],\"--\"); plt.plot(prob_pred, prob_true, marker=\"o\")\n",
    "plt.xlabel(\"Vorhergesagt\"); plt.ylabel(\"Tatsächlich\"); plt.title(f\"Kalibrierung (Test) – {CAL_METHOD}\")\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / \"calibration_test.png\", dpi=160); plt.close()\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(4.8,4.2))\n",
    "plt.imshow(cm, interpolation=\"nearest\"); plt.title(\"Confusion Matrix (Test)\"); plt.colorbar()\n",
    "ticks = np.arange(2); plt.xticks(ticks, [\"0\",\"1\"]); plt.yticks(ticks, [\"0\",\"1\"])\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / \"cm_test.png\", dpi=160); plt.close()\n",
    "\n",
    "# Histogramm Probas (einmalig, konsistent mit gewählter Kalibrierung)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(y_test_proba, bins=30, alpha=0.6, label=\"raw\")\n",
    "plt.hist(y_test_cal,   bins=30, alpha=0.6, label=f\"used ({CAL_METHOD})\")\n",
    "plt.axvline(thr, linestyle=\"--\", label=f\"thr={thr:.3f}\")\n",
    "plt.title(\"P(y=1) – raw vs. used (Test)\")\n",
    "plt.legend(); plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"proba_hist_raw_vs_used.png\", dpi=160); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "08cfd2af-70a6-4187-ab6f-c0ffb4d3c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Predictions-CSV ----------\n",
    "preds_test = pd.DataFrame({\n",
    "    \"timestamp\": idx_te, \"y_true\": yte,\n",
    "    \"y_proba_raw\": y_test_proba, \"y_proba_used\": y_test_cal, \"y_pred\": y_test_pred,\n",
    "}).set_index(\"timestamp\")\n",
    "preds_test.to_csv(RUN_DIR / \"preds_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ac31e9e3-bb48-4f08-b07b-01adcb99f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Backtest (Entry@t und @t+1) ----------\n",
    "close = df[\"close\"].copy()\n",
    "fwd_logret = (np.log(close.shift(-HORIZON)) - np.log(close)).reindex(idx_te)\n",
    "signals_t  = (preds_test[\"y_proba_used\"] >= thr).astype(int).reindex(idx_te)\n",
    "signals_t1 = signals_t.shift(1).fillna(0)\n",
    "\n",
    "strategy_logret_t  = (signals_t  * fwd_logret).fillna(0)\n",
    "strategy_logret_t1 = (signals_t1 * fwd_logret).fillna(0)\n",
    "equity_t  = strategy_logret_t.cumsum().apply(np.exp)\n",
    "equity_t1 = strategy_logret_t1.cumsum().apply(np.exp)\n",
    "\n",
    "bh_logret = (np.log(close.reindex(idx_te)) - np.log(close.reindex(idx_te).iloc[0])).fillna(0)\n",
    "bh_equity = np.exp(bh_logret)\n",
    "\n",
    "def _sharpe(logrets, periods_per_year=252):\n",
    "    mu = logrets.mean() * periods_per_year\n",
    "    sigma = logrets.std(ddof=1) * np.sqrt(periods_per_year)\n",
    "    return float(mu / (sigma + 1e-12))\n",
    "\n",
    "def _cagr(eq, periods_per_year=252):\n",
    "    T = len(eq) / periods_per_year\n",
    "    return float((eq.iloc[-1] / eq.iloc[0])**(1.0/T) - 1.0)\n",
    "\n",
    "backtest = {\n",
    "    \"n_trades\": int(signals_t.sum()),\n",
    "    \"avg_holding_h\": HORIZON,\n",
    "    \"strategy_t\":  {\"CAGR\": _cagr(equity_t),  \"Sharpe\": _sharpe(strategy_logret_t.dropna()),  \"final_equity\": float(equity_t.iloc[-1])},\n",
    "    \"strategy_t1\": {\"CAGR\": _cagr(equity_t1), \"Sharpe\": _sharpe(strategy_logret_t1.dropna()), \"final_equity\": float(equity_t1.iloc[-1])},\n",
    "    \"buy_hold\":    {\"CAGR\": _cagr(bh_equity), \"final_equity\": float(bh_equity.iloc[-1])},\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(equity_t.index, equity_t.values,   label=\"Entry@t (optimistisch)\")\n",
    "plt.plot(equity_t1.index, equity_t1.values, label=\"Entry@t+1 (konservativ)\")\n",
    "plt.plot(bh_equity.index, bh_equity.values, label=\"Buy & Hold\", linestyle=\"--\")\n",
    "plt.title(f\"Equity Curves (H={HORIZON})\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(FIG_DIR / \"equity_curves_t_vs_t1.png\", dpi=160); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "200036f8-d7ff-41fe-aa6f-ae6903888710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Block 4 abgeschlossen. Artefakte:\n",
      " - ..\\results\\2025-10-19_16-48-09_lstm\\preds_test.csv\n",
      " - ..\\results\\2025-10-19_16-48-09_lstm\\evaluation.json\n",
      " - ..\\results\\2025-10-19_16-48-09_lstm\\figures\n"
     ]
    }
   ],
   "source": [
    "# ---------- Evaluation Dump ----------\n",
    "out = {\n",
    "    \"config\": RCFG,\n",
    "    \"features_used\": FEATURES,\n",
    "    \"calibration\": {\n",
    "        \"chosen\": CAL_METHOD,\n",
    "        \"paths\": ({} if CAL_METHOD==\"none\" else {CAL_METHOD: str(RUN_DIR / f\"calibrator_{CAL_METHOD}.joblib\")}),\n",
    "        \"val_brier\": {\"raw\": float(brier_val_raw), \"iso\": float(brier_val_iso), \"platt\": float(brier_val_platt)},\n",
    "        \"test_brier\": {\"raw\": float(brier_raw), \"used\": float(brier_cal)}\n",
    "    },\n",
    "    \"label_resolved_from\": {\n",
    "    \"features_yaml\": f\"../data/features_{FEATURESET}.yml\",\n",
    "    \"ticker\": TICKER, \"interval\": INTERVAL, \"start\": START, \"end\": END,\n",
    "    \"horizon\": HORIZON, \"mode\": EPS_MODE, \"epsilon\": EPSILON\n",
    "    },\n",
    "    \"threshold_selection\": {\n",
    "        \"strategy\": \"max_mcc_with_pos_rate_bounds\",\n",
    "        \"threshold\": float(thr),\n",
    "        \"pos_rate_bounds\": [0.45, 0.55],\n",
    "        \"val_mcc\": float(score_val),\n",
    "        \"test_pred_pos_rate\": pos_rate_test\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        \"test\": {\n",
    "            \"roc_auc\": float(roc_auc), \"auprc\": float(ap), \"brier\": float(brier_cal),\n",
    "            \"balanced_accuracy\": float(bal_acc), \"mcc\": float(mcc),\n",
    "            \"confusion_matrix\": cm.tolist(), \"report\": rep\n",
    "        },\n",
    "        \"mcc_bootstrap_ci\": [float(x) for x in mcc_ci.tolist()]\n",
    "    },\n",
    "    \"backtest\": backtest,\n",
    "}\n",
    "with open(RUN_DIR / \"evaluation.json\", \"w\") as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "\n",
    "print(\"\\nBlock 4 abgeschlossen. Artefakte:\")\n",
    "print(\" -\", RUN_DIR / \"preds_test.csv\")\n",
    "print(\" -\", RUN_DIR / \"evaluation.json\")\n",
    "print(\" -\", RUN_DIR / \"figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c23181-39d6-4d12-b294-a152d62e251b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3852acd-f9d3-495d-b3ff-321f8a6f36c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (finance-lstm)",
   "language": "python",
   "name": "finance-lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
