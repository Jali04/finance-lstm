{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5df2c55f-8949-47a2-94b9-bb1bc25587a1",
   "metadata": {},
   "source": [
    "# -----------------------------------------\n",
    "# Block 4: Threshold-Tuning, Evaluation, Backtest & Plots\n",
    "# -----------------------------------------\n",
    "# Lädt die Artefakte aus dem letzten RUN_DIR, rekonstruiert\n",
    "# Val/Test-Splits, wählt einen optimalen Schwellenwert auf Val\n",
    "# (max. F1), evaluiert auf Test, erstellt Plots und einfachen Backtest.\n",
    "# -----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c69ddd0-9c11-473b-a3c9-56496d3485ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports & Setup ---\n",
    "import os, sys, json, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score,\n",
    "    classification_report, confusion_matrix, brier_score_loss,\n",
    "    balanced_accuracy_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.calibration import calibration_curve, IsotonicRegression\n",
    "import joblib\n",
    "\n",
    "ROOT = os.path.abspath(\"..\")\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c90c28-8087-4221-9a3e-466d5312eb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_DIR: ..\\results\\2025-10-14_16-59-43_lstm\n"
     ]
    }
   ],
   "source": [
    "# Config laden\n",
    "with open(os.path.join(ROOT, \"config.json\"), \"r\") as f:\n",
    "    C = json.load(f)\n",
    "TICKER, START, END, INTERVAL = C[\"ticker\"], C[\"start\"], C[\"end\"], C[\"interval\"]\n",
    "HORIZON, LOOKBACK = int(C[\"horizon\"]), int(C[\"lookback\"])\n",
    "BATCH, EPOCHS = int(C[\"batch\"]), int(C[\"epochs\"])\n",
    "SEED = int(C.get(\"seed\", 42))\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "RESULTS_DIR = Path(C.get(\"results_dir\", \"../results\"))\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _latest_run_dir(results_dir: Path) -> Path:\n",
    "    runs = sorted(results_dir.glob(\"*_lstm\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    if not runs:\n",
    "        raise FileNotFoundError(\"Kein RUN_DIR gefunden. Bitte Block 3 trainieren.\")\n",
    "    return runs[0]\n",
    "\n",
    "RUN_DIR = _latest_run_dir(RESULTS_DIR)\n",
    "print(\"RUN_DIR:\", RUN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70085932-0e7c-4267-a84a-55b823b98d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Artefakte laden ---\n",
    "MODEL_PATH  = RUN_DIR / \"model.keras\"\n",
    "SCALER_PATH = RUN_DIR / \"scaler.joblib\"\n",
    "CFG_PATH    = RUN_DIR / \"config.json\"\n",
    "assert MODEL_PATH.exists() and SCALER_PATH.exists() and CFG_PATH.exists(), \"Fehlende Artefakte.\"\n",
    "\n",
    "with open(CFG_PATH, \"r\") as f:\n",
    "    RCFG = json.load(f)\n",
    "\n",
    "# Konsistenz zur Laufzeit-Config\n",
    "assert int(RCFG[\"horizon\"]) == HORIZON and int(RCFG[\"lookback\"]) == LOOKBACK, \"Config-Mismatch.\"\n",
    "\n",
    "model  = keras.models.load_model(MODEL_PATH, compile=False)  # compile=False vermeidet _loss-Deser.\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "# --- Daten laden ---\n",
    "TRAIN_CSV = f\"../data/{TICKER}_{INTERVAL}_{START}_{END}_cls_h{HORIZON}.csv\"\n",
    "df = pd.read_csv(TRAIN_CSV, index_col=0, parse_dates=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0753df2d-817e-405e-ab22-a66be6d3f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature-Spalten bestimmen ---\n",
    "OHLCV = {\"open\",\"high\",\"low\",\"close\",\"volume\"}\n",
    "candidates = [c for c in df.columns if c not in (OHLCV | {\"target\"})]\n",
    "\n",
    "FEATURES = RCFG.get(\"features\", None)\n",
    "if FEATURES:\n",
    "    FEATURES = [c for c in FEATURES if c in candidates]\n",
    "else:\n",
    "    FEATURES = candidates\n",
    "assert len(FEATURES) > 0, f\"Keine Features gefunden. Kandidaten: {candidates}\"\n",
    "\n",
    "# X/y\n",
    "X = df[FEATURES].copy()\n",
    "y = df[\"target\"].astype(int).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24824a33-b6a3-4b61-b363-2551d40fda8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Chronologische Splits (70/15/15) ---\n",
    "n = len(df)\n",
    "n_train = int(n * 0.70); n_val = int(n * 0.15); n_test = n - n_train - n_val\n",
    "train_idx = slice(0, n_train)\n",
    "val_idx   = slice(n_train, n_train + n_val)\n",
    "test_idx  = slice(n_train + n_val, n)\n",
    "\n",
    "X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "X_val,   y_val   = X.iloc[val_idx],   y.iloc[val_idx]\n",
    "X_test,  y_test  = X.iloc[test_idx],  y.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6584d486-4b95-4f2c-a270-0fd2c5fc839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Skalierung (wie in Block 3: nur transformieren) ---\n",
    "X_train_s = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=FEATURES)\n",
    "X_val_s   = pd.DataFrame(scaler.transform(X_val),   index=X_val.index,   columns=FEATURES)\n",
    "X_test_s  = pd.DataFrame(scaler.transform(X_test),  index=X_test.index,  columns=FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aebd466-487b-4b3f-b3c5-f3dad3a88c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Windowing ---\n",
    "def make_windows(X_df: pd.DataFrame, y_ser: pd.Series, lookback: int):\n",
    "    X_values = X_df.values.astype(np.float32)\n",
    "    y_values = y_ser.values.astype(np.int32)\n",
    "    n = len(X_df)\n",
    "    xs, ys, idx_end = [], [], []\n",
    "    for i in range(lookback-1, n):\n",
    "        xs.append(X_values[i - lookback + 1 : i + 1])\n",
    "        ys.append(y_values[i])\n",
    "        idx_end.append(X_df.index[i])\n",
    "    return np.stack(xs, axis=0), np.array(ys), pd.DatetimeIndex(idx_end)\n",
    "\n",
    "Xtr_win, ytr, idx_tr = make_windows(X_train_s, y_train, LOOKBACK)\n",
    "Xva_win, yva, idx_va = make_windows(X_val_s,   y_val,   LOOKBACK)\n",
    "Xte_win, yte, idx_te = make_windows(X_test_s,  y_test,  LOOKBACK)\n",
    "\n",
    "def to_ds(X, y, batch, shuffle):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(X), seed=SEED, reshuffle_each_iteration=False)\n",
    "    return ds.batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_val  = to_ds(Xva_win, yva, BATCH, shuffle=False)\n",
    "ds_test = to_ds(Xte_win, yte, BATCH, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c71bb7ef-7955-4b2f-b901-68f04327ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Roh-Wahrscheinlichkeiten ---\n",
    "y_val_proba  = model.predict(ds_val,  verbose=0).ravel()\n",
    "y_test_proba = model.predict(ds_test, verbose=0).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f1ac0c3-a5b9-4799-bff4-7eff4450611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gewählter Threshold (Val, kalibriert): 0.500 | MCC_val=0.000\n"
     ]
    }
   ],
   "source": [
    "# --- Kalibrierung (Isotonic auf Val) ---\n",
    "iso = IsotonicRegression(out_of_bounds=\"clip\").fit(y_val_proba, yva)\n",
    "y_val_proba_cal  = iso.transform(y_val_proba)\n",
    "y_test_proba_cal = iso.transform(y_test_proba)\n",
    "joblib.dump(iso, RUN_DIR / \"calibrator.joblib\")\n",
    "\n",
    "# --- Schwellenwahl (Val) mit Pos-Rate-Korridor ---\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "def choose_threshold(y_true, y_prob, strategy=\"max_mcc\", pos_rate_bounds=(0.2, 0.8)):\n",
    "    uniq = np.unique(y_prob); cand = np.r_[0.0, uniq, 1.0]\n",
    "    best_t, best_s = 0.5, -1.0\n",
    "    for t in cand:\n",
    "        yp = (y_prob >= t).astype(int)\n",
    "        pr = float(yp.mean())\n",
    "        if not (pos_rate_bounds[0] <= pr <= pos_rate_bounds[1]):\n",
    "            continue\n",
    "        if strategy == \"max_mcc\":\n",
    "            s = matthews_corrcoef(y_true, yp)\n",
    "        else:\n",
    "            s = matthews_corrcoef(y_true, yp)\n",
    "        if s > best_s: best_s, best_t = float(s), float(t)\n",
    "    if best_s < 0:  # Fallback\n",
    "        return 0.5, 0.0\n",
    "    return best_t, best_s\n",
    "\n",
    "thr, score_val = choose_threshold(yva, y_val_proba_cal, strategy=\"max_mcc\", pos_rate_bounds=(0.2,0.8))\n",
    "print(f\"Gewählter Threshold (Val, kalibriert): {thr:.3f} | MCC_val={score_val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df77d65d-26fe-4609-898c-800dee5c857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (test):\n",
      " [[  4 204]\n",
      " [  6 238]]\n",
      "MCC: -0.018 BalancedAcc: 0.497 AUROC: 0.486 AUPRC: 0.534\n"
     ]
    }
   ],
   "source": [
    "# --- Test-Evaluation (kalibriert @ thr) ---\n",
    "y_test_pred = (y_test_proba_cal >= thr).astype(int)\n",
    "\n",
    "cm   = confusion_matrix(yte, y_test_pred)\n",
    "rep  = classification_report(yte, y_test_pred, digits=3, output_dict=True)\n",
    "fpr, tpr, _ = roc_curve(yte, y_test_proba_cal)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "prec, rec, _ = precision_recall_curve(yte, y_test_proba_cal)\n",
    "ap = average_precision_score(yte, y_test_proba_cal)\n",
    "brier_raw = brier_score_loss(yte, y_test_proba)       # vor Kal.\n",
    "brier_cal = brier_score_loss(yte, y_test_proba_cal)   # nach Kal.\n",
    "bal_acc = balanced_accuracy_score(yte, y_test_pred)\n",
    "mcc     = matthews_corrcoef(yte, y_test_pred)\n",
    "\n",
    "print(\"Confusion matrix (test):\\n\", cm)\n",
    "print(\"MCC:\", round(mcc,3), \"BalancedAcc:\", round(bal_acc,3), \"AUROC:\", round(roc_auc,3), \"AUPRC:\", round(ap,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1404cda-f83e-43b6-8e8b-e31d868a1ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC Bootstrap CI [2.5,50,97.5]: [np.float64(-0.059), np.float64(-0.008), np.float64(0.056)]\n"
     ]
    }
   ],
   "source": [
    "# --- Bootstrap-CI fürs MCC (Blocksampling) ---\n",
    "rng = np.random.default_rng(SEED)\n",
    "def block_bootstrap_mcc(y_true, y_prob, threshold, n=300, block=LOOKBACK):\n",
    "    idx = np.arange(len(y_true))\n",
    "    scores = []\n",
    "    for _ in range(n):\n",
    "        starts = rng.integers(0, max(1, len(idx)-block+1), size=max(1, len(idx)//block))\n",
    "        bs = np.concatenate([np.arange(s, min(s+block, len(idx))) for s in starts])\n",
    "        yp = (y_prob[bs] >= threshold).astype(int)\n",
    "        scores.append(matthews_corrcoef(y_true[bs], yp))\n",
    "    return np.percentile(scores, [2.5, 50, 97.5]).astype(float)\n",
    "mcc_ci = block_bootstrap_mcc(yte, y_test_proba_cal, thr, n=300, block=LOOKBACK)\n",
    "print(\"MCC Bootstrap CI [2.5,50,97.5]:\", [round(x,3) for x in mcc_ci])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "262a19eb-6fcf-415c-80ae-3eb318ce44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plots ---\n",
    "FIG_DIR = RUN_DIR / \"figures\"\n",
    "FIG_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "plt.figure(figsize=(6,4)); plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
    "plt.plot([0,1],[0,1],\"--\"); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC (Test)\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(FIG_DIR / \"roc_test.png\", dpi=160); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,4)); plt.plot(rec, prec, label=f\"AP={ap:.3f}\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall (Test)\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(FIG_DIR / \"pr_test.png\", dpi=160); plt.close()\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(yte, y_test_proba_cal, n_bins=10, strategy=\"quantile\")\n",
    "plt.figure(figsize=(6,4)); plt.plot([0,1],[0,1],\"--\"); plt.plot(prob_pred, prob_true, marker=\"o\")\n",
    "plt.xlabel(\"Vorhergesagt\"); plt.ylabel(\"Tatsächlich\"); plt.title(\"Kalibrierung (Test)\")\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / \"calibration_test.png\", dpi=160); plt.close()\n",
    "\n",
    "plt.figure(figsize=(4.8,4.2))\n",
    "plt.imshow(cm, interpolation=\"nearest\"); plt.title(\"Confusion Matrix (Test)\"); plt.colorbar()\n",
    "ticks = np.arange(2); plt.xticks(ticks, [\"0\",\"1\"]); plt.yticks(ticks, [\"0\",\"1\"])\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / \"cm_test.png\", dpi=160); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(y_test_proba, bins=30, alpha=0.6, label=\"raw\")\n",
    "plt.hist(y_test_proba_cal, bins=30, alpha=0.6, label=\"calibrated (isotonic)\")\n",
    "plt.axvline(thr, linestyle=\"--\", label=f\"thr={thr:.3f}\")\n",
    "plt.title(\"P(y=1) Verteilung (Test) – roh vs. kalibriert\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(FIG_DIR / \"proba_hist_raw_vs_cal.png\", dpi=160); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08cfd2af-70a6-4187-ab6f-c0ffb4d3c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Predictions-CSV (Test, kalibriert) ---\n",
    "preds_test = pd.DataFrame({\n",
    "    \"timestamp\": idx_te,\n",
    "    \"y_true\": yte,\n",
    "    \"y_proba_raw\": y_test_proba,\n",
    "    \"y_proba_cal\": y_test_proba_cal,\n",
    "    \"y_pred\": y_test_pred,\n",
    "}).set_index(\"timestamp\")\n",
    "preds_test.to_csv(RUN_DIR / \"preds_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac31e9e3-bb48-4f08-b07b-01adcb99f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Einfache Handels-Strategien (Entry @t und @t+1) ---\n",
    "close = df[\"close\"].copy()\n",
    "fwd_logret = (np.log(close.shift(-HORIZON)) - np.log(close)).reindex(idx_te)\n",
    "\n",
    "signals_t  = (preds_test[\"y_proba_cal\"] >= thr).astype(int).reindex(idx_te)\n",
    "signals_t1 = signals_t.shift(1).fillna(0)\n",
    "\n",
    "strategy_logret_t  = (signals_t  * fwd_logret).fillna(0)\n",
    "strategy_logret_t1 = (signals_t1 * fwd_logret).fillna(0)\n",
    "\n",
    "equity_t  = strategy_logret_t.cumsum().apply(np.exp)\n",
    "equity_t1 = strategy_logret_t1.cumsum().apply(np.exp)\n",
    "\n",
    "bh_logret = (np.log(close.reindex(idx_te)) - np.log(close.reindex(idx_te).iloc[0])).fillna(0)\n",
    "bh_equity = np.exp(bh_logret)\n",
    "\n",
    "def _sharpe(logrets, periods_per_year=252):\n",
    "    if len(logrets) < 2: return float(\"nan\")\n",
    "    mu = logrets.mean() * periods_per_year\n",
    "    sigma = logrets.std(ddof=1) * np.sqrt(periods_per_year)\n",
    "    return float(mu / (sigma + 1e-12))\n",
    "\n",
    "def _cagr(equity_series, periods_per_year=252):\n",
    "    if len(equity_series) < 2: return float(\"nan\")\n",
    "    T = len(equity_series) / periods_per_year\n",
    "    return float((equity_series.iloc[-1] / equity_series.iloc[0])**(1.0/T) - 1.0)\n",
    "\n",
    "backtest = {\n",
    "    \"n_trades\": int(signals_t.sum()),\n",
    "    \"avg_holding_h\": HORIZON,\n",
    "    \"strategy_t\": {\n",
    "        \"CAGR\": _cagr(equity_t),\n",
    "        \"Sharpe\": _sharpe(strategy_logret_t.dropna()),\n",
    "        \"final_equity\": float(equity_t.iloc[-1]),\n",
    "    },\n",
    "    \"strategy_t1\": {\n",
    "        \"CAGR\": _cagr(equity_t1),\n",
    "        \"Sharpe\": _sharpe(strategy_logret_t1.dropna()),\n",
    "        \"final_equity\": float(equity_t1.iloc[-1]),\n",
    "    },\n",
    "    \"buy_hold\": {\n",
    "        \"CAGR\": _cagr(bh_equity),\n",
    "        \"final_equity\": float(bh_equity.iloc[-1]),\n",
    "    },\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(equity_t.index, equity_t.values,   label=\"Entry@t (optimistisch)\")\n",
    "plt.plot(equity_t1.index, equity_t1.values, label=\"Entry@t+1 (konservativ)\")\n",
    "plt.plot(bh_equity.index, bh_equity.values, label=\"Buy & Hold\", linestyle=\"--\")\n",
    "plt.title(f\"Equity Curves (H={HORIZON})\")\n",
    "plt.legend(); plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"equity_curves_t_vs_t1.png\", dpi=160); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.boxplot([fwd_logret[signals_t==0].dropna(), fwd_logret[signals_t==1].dropna()],\n",
    "            tick_labels=[\"Signal=0\",\"Signal=1\"])\n",
    "plt.title(\"Forward Log-Return nach Signal\")\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / \"forward_returns_by_signal.png\", dpi=160); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0a1c3dd-3650-4c1e-845e-63c98a6421e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier raw=0.2523 → calibrated=0.2571\n"
     ]
    }
   ],
   "source": [
    "# --- Vor/Nach: Histogramm + Brier ---\n",
    "calib_name = \"isotonic\"  # oder aus deiner Pipeline lesen\n",
    "\n",
    "brier_raw = brier_score_loss(yte, y_test_proba)\n",
    "brier_cal = brier_score_loss(yte, y_test_proba_cal)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(y_test_proba,      bins=30, alpha=0.6, label=\"raw\")\n",
    "plt.hist(y_test_proba_cal,  bins=30, alpha=0.6, label=f\"calibrated ({calib_name})\")\n",
    "plt.axvline(thr, linestyle=\"--\", label=f\"thr={thr:.3f}\")\n",
    "plt.title(\"P(y=1) – raw vs. calibrated (Test)\")\n",
    "plt.legend(); plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"proba_hist_raw_vs_cal.png\", dpi=160); plt.close()\n",
    "\n",
    "print(f\"Brier raw={brier_raw:.4f} → calibrated={brier_cal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "200036f8-d7ff-41fe-aa6f-ae6903888710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Block 4 abgeschlossen.\n",
      "Artefakte:\n",
      " - ..\\results\\2025-10-14_16-59-43_lstm\\preds_test.csv\n",
      " - ..\\results\\2025-10-14_16-59-43_lstm\\evaluation.json\n",
      " - ..\\results\\2025-10-14_16-59-43_lstm\\figures\n"
     ]
    }
   ],
   "source": [
    "# --- Ergebnisse schreiben ---\n",
    "out = {\n",
    "    \"config\": RCFG,\n",
    "    \"features_used\": FEATURES,\n",
    "    \"threshold_selection\": {\n",
    "        \"strategy\": \"max_mcc_with_pos_rate_bounds\",\n",
    "        \"threshold\": float(thr),\n",
    "        \"pos_rate_bounds\": [0.2, 0.8],\n",
    "        \"val_mcc\": float(score_val),\n",
    "    },\n",
    "    \"calibration\": {\"method\": \"isotonic\", \"path\": str(RUN_DIR / \"calibrator.joblib\"),\n",
    "                    \"brier_raw\": float(brier_raw), \"brier_cal\": float(brier_cal)},\n",
    "    \"metrics\": {\n",
    "        \"test\": {\n",
    "            \"roc_auc\": float(roc_auc),\n",
    "            \"auprc\": float(ap),\n",
    "            \"brier\": float(brier_cal),\n",
    "            \"balanced_accuracy\": float(bal_acc),\n",
    "            \"mcc\": float(mcc),\n",
    "            \"mcc_bootstrap_ci\": [float(mcc_ci[0]), float(mcc_ci[1]), float(mcc_ci[2])],\n",
    "            \"confusion_matrix\": cm.tolist(),\n",
    "            \"report\": rep,\n",
    "        }\n",
    "    },\n",
    "    \"diagnostics\": {\n",
    "        \"val_pos_rate_cal\": float(y_val_proba_cal.mean()),\n",
    "        \"test_pos_rate_cal\": float(y_test_proba_cal.mean()),\n",
    "        \"test_pred_pos_rate_at_thr\": float((y_test_proba_cal >= thr).mean()),\n",
    "    },\n",
    "    \"backtest\": backtest,\n",
    "}\n",
    "with open(RUN_DIR / \"evaluation.json\", \"w\") as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "\n",
    "print(\"\\nBlock 4 abgeschlossen.\")\n",
    "print(\"Artefakte:\")\n",
    "print(\" -\", RUN_DIR / \"preds_test.csv\")\n",
    "print(\" -\", RUN_DIR / \"evaluation.json\")\n",
    "print(\" -\", RUN_DIR / \"figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c23181-39d6-4d12-b294-a152d62e251b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3852acd-f9d3-495d-b3ff-321f8a6f36c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (finance-lstm)",
   "language": "python",
   "name": "finance-lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
